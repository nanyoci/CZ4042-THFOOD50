Found 12720 files belonging to 50 classes.
Found 1413 files belonging to 50 classes.
Found 1597 files belonging to 50 classes.
Model: "model"
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            [(None, 224, 224, 3) 0                                            
__________________________________________________________________________________________________
conv1 (Conv2D)                  (None, 112, 112, 64) 4864        input_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization (BatchNorma (None, 112, 112, 64) 256         conv1[0][0]                      
__________________________________________________________________________________________________
activation (Activation)         (None, 112, 112, 64) 0           batch_normalization[0][0]        
__________________________________________________________________________________________________
pool1 (MaxPooling2D)            (None, 55, 55, 64)   0           activation[0][0]                 
__________________________________________________________________________________________________
nu_inception_1_3x3_reduce (Conv (None, 55, 55, 24)   1560        pool1[0][0]                      
__________________________________________________________________________________________________
nu_inception_1_5x5_reduce (Conv (None, 55, 55, 4)    260         pool1[0][0]                      
__________________________________________________________________________________________________
batch_normalization_2 (BatchNor (None, 55, 55, 24)   96          nu_inception_1_3x3_reduce[0][0]  
__________________________________________________________________________________________________
batch_normalization_4 (BatchNor (None, 55, 55, 4)    16          nu_inception_1_5x5_reduce[0][0]  
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 55, 55, 24)   0           batch_normalization_2[0][0]      
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 55, 55, 4)    0           batch_normalization_4[0][0]      
__________________________________________________________________________________________________
nu_inception_1_maxpool (MaxPool (None, 55, 55, 64)   0           pool1[0][0]                      
__________________________________________________________________________________________________
nu_inception_1_1x1 (Conv2D)     (None, 55, 55, 16)   1040        pool1[0][0]                      
__________________________________________________________________________________________________
nu_inception_1_3x3 (Conv2D)     (None, 55, 55, 32)   6944        activation_2[0][0]               
__________________________________________________________________________________________________
nu_inception_1_5x5 (Conv2D)     (None, 55, 55, 8)    296         activation_4[0][0]               
__________________________________________________________________________________________________
nu_inception_1_1x1_0 (Conv2D)   (None, 55, 55, 8)    520         nu_inception_1_maxpool[0][0]     
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 55, 55, 16)   64          nu_inception_1_1x1[0][0]         
__________________________________________________________________________________________________
batch_normalization_3 (BatchNor (None, 55, 55, 32)   128         nu_inception_1_3x3[0][0]         
__________________________________________________________________________________________________
batch_normalization_5 (BatchNor (None, 55, 55, 8)    32          nu_inception_1_5x5[0][0]         
__________________________________________________________________________________________________
batch_normalization_6 (BatchNor (None, 55, 55, 8)    32          nu_inception_1_1x1_0[0][0]       
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 55, 55, 16)   0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 55, 55, 32)   0           batch_normalization_3[0][0]      
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 55, 55, 8)    0           batch_normalization_5[0][0]      
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 55, 55, 8)    0           batch_normalization_6[0][0]      
__________________________________________________________________________________________________
concatenate (Concatenate)       (None, 55, 55, 64)   0           activation_1[0][0]               
                                                                 activation_3[0][0]               
                                                                 activation_5[0][0]               
                                                                 activation_6[0][0]               
__________________________________________________________________________________________________
conv_direct_1 (Conv2D)          (None, 55, 55, 64)   4160        concatenate[0][0]                
__________________________________________________________________________________________________
conv_bypass_1 (Conv2D)          (None, 55, 55, 64)   4160        pool1[0][0]                      
__________________________________________________________________________________________________
batch_normalization_7 (BatchNor (None, 55, 55, 64)   256         conv_direct_1[0][0]              
__________________________________________________________________________________________________
batch_normalization_8 (BatchNor (None, 55, 55, 64)   256         conv_bypass_1[0][0]              
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 55, 55, 64)   0           batch_normalization_7[0][0]      
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 55, 55, 64)   0           batch_normalization_8[0][0]      
__________________________________________________________________________________________________
residual1 (Add)                 (None, 55, 55, 64)   0           activation_7[0][0]               
                                                                 activation_8[0][0]               
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 55, 55, 64)   0           residual1[0][0]                  
__________________________________________________________________________________________________
pool2 (MaxPooling2D)            (None, 27, 27, 64)   0           activation_9[0][0]               
__________________________________________________________________________________________________
nu_inception_2_3x3_reduce (Conv (None, 27, 27, 48)   3120        pool2[0][0]                      
__________________________________________________________________________________________________
nu_inception_2_5x5_reduce (Conv (None, 27, 27, 8)    520         pool2[0][0]                      
__________________________________________________________________________________________________
batch_normalization_10 (BatchNo (None, 27, 27, 48)   192         nu_inception_2_3x3_reduce[0][0]  
__________________________________________________________________________________________________
batch_normalization_12 (BatchNo (None, 27, 27, 8)    32          nu_inception_2_5x5_reduce[0][0]  
__________________________________________________________________________________________________
activation_11 (Activation)      (None, 27, 27, 48)   0           batch_normalization_10[0][0]     
__________________________________________________________________________________________________
activation_13 (Activation)      (None, 27, 27, 8)    0           batch_normalization_12[0][0]     
__________________________________________________________________________________________________
nu_inception_2_maxpool (MaxPool (None, 27, 27, 64)   0           pool2[0][0]                      
__________________________________________________________________________________________________
nu_inception_2_1x1 (Conv2D)     (None, 27, 27, 32)   2080        pool2[0][0]                      
__________________________________________________________________________________________________
nu_inception_2_3x3 (Conv2D)     (None, 27, 27, 64)   27712       activation_11[0][0]              
__________________________________________________________________________________________________
nu_inception_2_5x5 (Conv2D)     (None, 27, 27, 16)   1168        activation_13[0][0]              
__________________________________________________________________________________________________
nu_inception_2_1x1_0 (Conv2D)   (None, 27, 27, 16)   1040        nu_inception_2_maxpool[0][0]     
__________________________________________________________________________________________________
batch_normalization_9 (BatchNor (None, 27, 27, 32)   128         nu_inception_2_1x1[0][0]         
__________________________________________________________________________________________________
batch_normalization_11 (BatchNo (None, 27, 27, 64)   256         nu_inception_2_3x3[0][0]         
__________________________________________________________________________________________________
batch_normalization_13 (BatchNo (None, 27, 27, 16)   64          nu_inception_2_5x5[0][0]         
__________________________________________________________________________________________________
batch_normalization_14 (BatchNo (None, 27, 27, 16)   64          nu_inception_2_1x1_0[0][0]       
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 27, 27, 32)   0           batch_normalization_9[0][0]      
__________________________________________________________________________________________________
activation_12 (Activation)      (None, 27, 27, 64)   0           batch_normalization_11[0][0]     
__________________________________________________________________________________________________
activation_14 (Activation)      (None, 27, 27, 16)   0           batch_normalization_13[0][0]     
__________________________________________________________________________________________________
activation_15 (Activation)      (None, 27, 27, 16)   0           batch_normalization_14[0][0]     
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 27, 27, 128)  0           activation_10[0][0]              
                                                                 activation_12[0][0]              
                                                                 activation_14[0][0]              
                                                                 activation_15[0][0]              
__________________________________________________________________________________________________
conv_direct_2 (Conv2D)          (None, 27, 27, 128)  16512       concatenate_1[0][0]              
__________________________________________________________________________________________________
conv_bypass_2 (Conv2D)          (None, 27, 27, 128)  8320        pool2[0][0]                      
__________________________________________________________________________________________________
batch_normalization_15 (BatchNo (None, 27, 27, 128)  512         conv_direct_2[0][0]              
__________________________________________________________________________________________________
batch_normalization_16 (BatchNo (None, 27, 27, 128)  512         conv_bypass_2[0][0]              
__________________________________________________________________________________________________
activation_16 (Activation)      (None, 27, 27, 128)  0           batch_normalization_15[0][0]     
__________________________________________________________________________________________________
activation_17 (Activation)      (None, 27, 27, 128)  0           batch_normalization_16[0][0]     
__________________________________________________________________________________________________
residual2 (Add)                 (None, 27, 27, 128)  0           activation_16[0][0]              
                                                                 activation_17[0][0]              
__________________________________________________________________________________________________
activation_18 (Activation)      (None, 27, 27, 128)  0           residual2[0][0]                  
__________________________________________________________________________________________________
pool3 (MaxPooling2D)            (None, 13, 13, 128)  0           activation_18[0][0]              
__________________________________________________________________________________________________
nu_inception_3_3x3_reduce (Conv (None, 13, 13, 96)   12384       pool3[0][0]                      
__________________________________________________________________________________________________
nu_inception_3_5x5_reduce (Conv (None, 13, 13, 16)   2064        pool3[0][0]                      
__________________________________________________________________________________________________
batch_normalization_18 (BatchNo (None, 13, 13, 96)   384         nu_inception_3_3x3_reduce[0][0]  
__________________________________________________________________________________________________
batch_normalization_20 (BatchNo (None, 13, 13, 16)   64          nu_inception_3_5x5_reduce[0][0]  
__________________________________________________________________________________________________
activation_20 (Activation)      (None, 13, 13, 96)   0           batch_normalization_18[0][0]     
__________________________________________________________________________________________________
activation_22 (Activation)      (None, 13, 13, 16)   0           batch_normalization_20[0][0]     
__________________________________________________________________________________________________
nu_inception_3_maxpool (MaxPool (None, 13, 13, 128)  0           pool3[0][0]                      
__________________________________________________________________________________________________
nu_inception_3_1x1 (Conv2D)     (None, 13, 13, 64)   8256        pool3[0][0]                      
__________________________________________________________________________________________________
nu_inception_3_3x3 (Conv2D)     (None, 13, 13, 128)  110720      activation_20[0][0]              
__________________________________________________________________________________________________
nu_inception_3_5x5 (Conv2D)     (None, 13, 13, 32)   4640        activation_22[0][0]              
__________________________________________________________________________________________________
nu_inception_3_1x1_0 (Conv2D)   (None, 13, 13, 32)   4128        nu_inception_3_maxpool[0][0]     
__________________________________________________________________________________________________
batch_normalization_17 (BatchNo (None, 13, 13, 64)   256         nu_inception_3_1x1[0][0]         
__________________________________________________________________________________________________
batch_normalization_19 (BatchNo (None, 13, 13, 128)  512         nu_inception_3_3x3[0][0]         
__________________________________________________________________________________________________
batch_normalization_21 (BatchNo (None, 13, 13, 32)   128         nu_inception_3_5x5[0][0]         
__________________________________________________________________________________________________
batch_normalization_22 (BatchNo (None, 13, 13, 32)   128         nu_inception_3_1x1_0[0][0]       
__________________________________________________________________________________________________
activation_19 (Activation)      (None, 13, 13, 64)   0           batch_normalization_17[0][0]     
__________________________________________________________________________________________________
activation_21 (Activation)      (None, 13, 13, 128)  0           batch_normalization_19[0][0]     
__________________________________________________________________________________________________
activation_23 (Activation)      (None, 13, 13, 32)   0           batch_normalization_21[0][0]     
__________________________________________________________________________________________________
activation_24 (Activation)      (None, 13, 13, 32)   0           batch_normalization_22[0][0]     
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 13, 13, 256)  0           activation_19[0][0]              
                                                                 activation_21[0][0]              
                                                                 activation_23[0][0]              
                                                                 activation_24[0][0]              
__________________________________________________________________________________________________
conv_direct_3 (Conv2D)          (None, 13, 13, 256)  65792       concatenate_2[0][0]              
__________________________________________________________________________________________________
conv_bypass_3 (Conv2D)          (None, 13, 13, 256)  33024       pool3[0][0]                      
__________________________________________________________________________________________________
batch_normalization_23 (BatchNo (None, 13, 13, 256)  1024        conv_direct_3[0][0]              
__________________________________________________________________________________________________
batch_normalization_24 (BatchNo (None, 13, 13, 256)  1024        conv_bypass_3[0][0]              
__________________________________________________________________________________________________
activation_25 (Activation)      (None, 13, 13, 256)  0           batch_normalization_23[0][0]     
__________________________________________________________________________________________________
activation_26 (Activation)      (None, 13, 13, 256)  0           batch_normalization_24[0][0]     
__________________________________________________________________________________________________
residual3 (Add)                 (None, 13, 13, 256)  0           activation_25[0][0]              
                                                                 activation_26[0][0]              
__________________________________________________________________________________________________
activation_27 (Activation)      (None, 13, 13, 256)  0           residual3[0][0]                  
__________________________________________________________________________________________________
pool4 (MaxPooling2D)            (None, 6, 6, 256)    0           activation_27[0][0]              
__________________________________________________________________________________________________
nu_inception_4_3x3_reduce (Conv (None, 6, 6, 192)    49344       pool4[0][0]                      
__________________________________________________________________________________________________
nu_inception_4_5x5_reduce (Conv (None, 6, 6, 32)     8224        pool4[0][0]                      
__________________________________________________________________________________________________
batch_normalization_26 (BatchNo (None, 6, 6, 192)    768         nu_inception_4_3x3_reduce[0][0]  
__________________________________________________________________________________________________
batch_normalization_28 (BatchNo (None, 6, 6, 32)     128         nu_inception_4_5x5_reduce[0][0]  
__________________________________________________________________________________________________
activation_29 (Activation)      (None, 6, 6, 192)    0           batch_normalization_26[0][0]     
__________________________________________________________________________________________________
activation_31 (Activation)      (None, 6, 6, 32)     0           batch_normalization_28[0][0]     
__________________________________________________________________________________________________
nu_inception_4_maxpool (MaxPool (None, 6, 6, 256)    0           pool4[0][0]                      
__________________________________________________________________________________________________
nu_inception_4_1x1 (Conv2D)     (None, 6, 6, 128)    32896       pool4[0][0]                      
__________________________________________________________________________________________________
nu_inception_4_3x3 (Conv2D)     (None, 6, 6, 256)    442624      activation_29[0][0]              
__________________________________________________________________________________________________
nu_inception_4_5x5 (Conv2D)     (None, 6, 6, 64)     18496       activation_31[0][0]              
__________________________________________________________________________________________________
nu_inception_4_1x1_0 (Conv2D)   (None, 6, 6, 64)     16448       nu_inception_4_maxpool[0][0]     
__________________________________________________________________________________________________
batch_normalization_25 (BatchNo (None, 6, 6, 128)    512         nu_inception_4_1x1[0][0]         
__________________________________________________________________________________________________
batch_normalization_27 (BatchNo (None, 6, 6, 256)    1024        nu_inception_4_3x3[0][0]         
__________________________________________________________________________________________________
batch_normalization_29 (BatchNo (None, 6, 6, 64)     256         nu_inception_4_5x5[0][0]         
__________________________________________________________________________________________________
batch_normalization_30 (BatchNo (None, 6, 6, 64)     256         nu_inception_4_1x1_0[0][0]       
__________________________________________________________________________________________________
activation_28 (Activation)      (None, 6, 6, 128)    0           batch_normalization_25[0][0]     
__________________________________________________________________________________________________
activation_30 (Activation)      (None, 6, 6, 256)    0           batch_normalization_27[0][0]     
__________________________________________________________________________________________________
activation_32 (Activation)      (None, 6, 6, 64)     0           batch_normalization_29[0][0]     
__________________________________________________________________________________________________
activation_33 (Activation)      (None, 6, 6, 64)     0           batch_normalization_30[0][0]     
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 6, 6, 512)    0           activation_28[0][0]              
                                                                 activation_30[0][0]              
                                                                 activation_32[0][0]              
                                                                 activation_33[0][0]              
__________________________________________________________________________________________________
conv_direct_4 (Conv2D)          (None, 6, 6, 512)    262656      concatenate_3[0][0]              
__________________________________________________________________________________________________
conv_bypass_4 (Conv2D)          (None, 6, 6, 512)    131584      pool4[0][0]                      
__________________________________________________________________________________________________
batch_normalization_31 (BatchNo (None, 6, 6, 512)    2048        conv_direct_4[0][0]              
__________________________________________________________________________________________________
batch_normalization_32 (BatchNo (None, 6, 6, 512)    2048        conv_bypass_4[0][0]              
__________________________________________________________________________________________________
activation_34 (Activation)      (None, 6, 6, 512)    0           batch_normalization_31[0][0]     
__________________________________________________________________________________________________
activation_35 (Activation)      (None, 6, 6, 512)    0           batch_normalization_32[0][0]     
__________________________________________________________________________________________________
residual4 (Add)                 (None, 6, 6, 512)    0           activation_34[0][0]              
                                                                 activation_35[0][0]              
__________________________________________________________________________________________________
activation_36 (Activation)      (None, 6, 6, 512)    0           residual4[0][0]                  
__________________________________________________________________________________________________
avg_pool (GlobalAveragePooling2 (None, 512)          0           activation_36[0][0]              
__________________________________________________________________________________________________
dense (Dense)                   (None, 50)           25650       avg_pool[0][0]                   
==================================================================================================
Total params: 1,326,662
Trainable params: 1,319,934
Non-trainable params: 6,728
__________________________________________________________________________________________________
Epoch 1/100
199/199 - 88s - loss: 4.8643 - accuracy: 0.1895 - val_loss: 4.4765 - val_accuracy: 0.2024

Epoch 00001: val_loss improved from inf to 4.47651, saving model to modified_v2_training/cp.ckpt
Epoch 2/100
199/199 - 12s - loss: 3.3643 - accuracy: 0.3707 - val_loss: 7.6115 - val_accuracy: 0.0920

Epoch 00002: val_loss did not improve from 4.47651
Epoch 3/100
199/199 - 12s - loss: 2.7866 - accuracy: 0.4491 - val_loss: 4.1549 - val_accuracy: 0.2739

Epoch 00003: val_loss improved from 4.47651 to 4.15494, saving model to modified_v2_training/cp.ckpt
Epoch 4/100
199/199 - 12s - loss: 2.3908 - accuracy: 0.5134 - val_loss: 3.7639 - val_accuracy: 0.2527

Epoch 00004: val_loss improved from 4.15494 to 3.76386, saving model to modified_v2_training/cp.ckpt
Epoch 5/100
199/199 - 12s - loss: 2.1342 - accuracy: 0.5628 - val_loss: 3.9389 - val_accuracy: 0.2647

Epoch 00005: val_loss did not improve from 3.76386
Epoch 6/100
199/199 - 12s - loss: 1.9923 - accuracy: 0.5881 - val_loss: 3.8179 - val_accuracy: 0.2711

Epoch 00006: val_loss did not improve from 3.76386
Epoch 7/100
199/199 - 12s - loss: 1.8557 - accuracy: 0.6127 - val_loss: 4.0240 - val_accuracy: 0.2675

Epoch 00007: val_loss did not improve from 3.76386
Epoch 8/100
199/199 - 12s - loss: 1.7561 - accuracy: 0.6451 - val_loss: 3.9112 - val_accuracy: 0.2321

Epoch 00008: val_loss did not improve from 3.76386
Epoch 9/100
199/199 - 12s - loss: 1.6973 - accuracy: 0.6539 - val_loss: 3.6308 - val_accuracy: 0.3057

Epoch 00009: val_loss improved from 3.76386 to 3.63080, saving model to modified_v2_training/cp.ckpt
Epoch 10/100
199/199 - 12s - loss: 1.6400 - accuracy: 0.6723 - val_loss: 6.4419 - val_accuracy: 0.0941

Epoch 00010: val_loss did not improve from 3.63080
Epoch 11/100
199/199 - 12s - loss: 1.5867 - accuracy: 0.6952 - val_loss: 3.2414 - val_accuracy: 0.3701

Epoch 00011: val_loss improved from 3.63080 to 3.24143, saving model to modified_v2_training/cp.ckpt
Epoch 12/100
199/199 - 12s - loss: 1.5683 - accuracy: 0.7049 - val_loss: 3.2075 - val_accuracy: 0.3666

Epoch 00012: val_loss improved from 3.24143 to 3.20752, saving model to modified_v2_training/cp.ckpt
Epoch 13/100
199/199 - 12s - loss: 1.5380 - accuracy: 0.7100 - val_loss: 3.4456 - val_accuracy: 0.3659

Epoch 00013: val_loss did not improve from 3.20752
Epoch 14/100
199/199 - 12s - loss: 1.5058 - accuracy: 0.7258 - val_loss: 4.6662 - val_accuracy: 0.2647

Epoch 00014: val_loss did not improve from 3.20752
Epoch 15/100
199/199 - 12s - loss: 1.4883 - accuracy: 0.7316 - val_loss: 4.1636 - val_accuracy: 0.2916

Epoch 00015: val_loss did not improve from 3.20752
Epoch 16/100
199/199 - 12s - loss: 1.4589 - accuracy: 0.7445 - val_loss: 6.7405 - val_accuracy: 0.1430

Epoch 00016: val_loss did not improve from 3.20752
Epoch 17/100
199/199 - 12s - loss: 1.4455 - accuracy: 0.7503 - val_loss: 3.7594 - val_accuracy: 0.4161

Epoch 00017: val_loss did not improve from 3.20752
Epoch 18/100
199/199 - 12s - loss: 1.4193 - accuracy: 0.7589 - val_loss: 4.4139 - val_accuracy: 0.2972

Epoch 00018: val_loss did not improve from 3.20752
Epoch 19/100
199/199 - 12s - loss: 1.4441 - accuracy: 0.7585 - val_loss: 6.4923 - val_accuracy: 0.2130

Epoch 00019: val_loss did not improve from 3.20752
Epoch 20/100
199/199 - 12s - loss: 1.4215 - accuracy: 0.7674 - val_loss: 6.9209 - val_accuracy: 0.1783

Epoch 00020: val_loss did not improve from 3.20752
Epoch 21/100
199/199 - 12s - loss: 1.4080 - accuracy: 0.7741 - val_loss: 3.2338 - val_accuracy: 0.3708

Epoch 00021: val_loss did not improve from 3.20752
Epoch 22/100
199/199 - 12s - loss: 1.3770 - accuracy: 0.7829 - val_loss: 4.5735 - val_accuracy: 0.2817

Epoch 00022: val_loss did not improve from 3.20752
Epoch 23/100
199/199 - 12s - loss: 1.3834 - accuracy: 0.7865 - val_loss: 5.7537 - val_accuracy: 0.2243

Epoch 00023: val_loss did not improve from 3.20752
Epoch 24/100
199/199 - 12s - loss: 1.3586 - accuracy: 0.8009 - val_loss: 6.1767 - val_accuracy: 0.1691

Epoch 00024: val_loss did not improve from 3.20752
Epoch 25/100
199/199 - 12s - loss: 1.3617 - accuracy: 0.7942 - val_loss: 4.7552 - val_accuracy: 0.2873

Epoch 00025: val_loss did not improve from 3.20752
Epoch 26/100
199/199 - 12s - loss: 1.1117 - accuracy: 0.8873 - val_loss: 1.7491 - val_accuracy: 0.7006

Epoch 00026: val_loss improved from 3.20752 to 1.74905, saving model to modified_v2_training/cp.ckpt
Epoch 27/100
199/199 - 12s - loss: 0.8692 - accuracy: 0.9656 - val_loss: 1.6744 - val_accuracy: 0.7148

Epoch 00027: val_loss improved from 1.74905 to 1.67442, saving model to modified_v2_training/cp.ckpt
Epoch 28/100
199/199 - 12s - loss: 0.7949 - accuracy: 0.9807 - val_loss: 1.5984 - val_accuracy: 0.7396

Epoch 00028: val_loss improved from 1.67442 to 1.59839, saving model to modified_v2_training/cp.ckpt
Epoch 29/100
199/199 - 12s - loss: 0.7402 - accuracy: 0.9884 - val_loss: 1.5243 - val_accuracy: 0.7502

Epoch 00029: val_loss improved from 1.59839 to 1.52435, saving model to modified_v2_training/cp.ckpt
Epoch 30/100
199/199 - 12s - loss: 0.6965 - accuracy: 0.9935 - val_loss: 1.5171 - val_accuracy: 0.7544

Epoch 00030: val_loss improved from 1.52435 to 1.51711, saving model to modified_v2_training/cp.ckpt
Epoch 31/100
199/199 - 12s - loss: 0.6588 - accuracy: 0.9953 - val_loss: 1.4947 - val_accuracy: 0.7580

Epoch 00031: val_loss improved from 1.51711 to 1.49466, saving model to modified_v2_training/cp.ckpt
Epoch 32/100
199/199 - 12s - loss: 0.6258 - accuracy: 0.9970 - val_loss: 1.4980 - val_accuracy: 0.7459

Epoch 00032: val_loss did not improve from 1.49466
Epoch 33/100
199/199 - 12s - loss: 0.5955 - accuracy: 0.9983 - val_loss: 1.4486 - val_accuracy: 0.7622

Epoch 00033: val_loss improved from 1.49466 to 1.44857, saving model to modified_v2_training/cp.ckpt
Epoch 34/100
199/199 - 12s - loss: 0.5681 - accuracy: 0.9987 - val_loss: 1.4430 - val_accuracy: 0.7686

Epoch 00034: val_loss improved from 1.44857 to 1.44300, saving model to modified_v2_training/cp.ckpt
Epoch 35/100
199/199 - 12s - loss: 0.5425 - accuracy: 0.9992 - val_loss: 1.4298 - val_accuracy: 0.7587

Epoch 00035: val_loss improved from 1.44300 to 1.42978, saving model to modified_v2_training/cp.ckpt
Epoch 36/100
199/199 - 12s - loss: 0.5187 - accuracy: 0.9993 - val_loss: 1.4078 - val_accuracy: 0.7636

Epoch 00036: val_loss improved from 1.42978 to 1.40779, saving model to modified_v2_training/cp.ckpt
Epoch 37/100
199/199 - 12s - loss: 0.4964 - accuracy: 0.9998 - val_loss: 1.4093 - val_accuracy: 0.7622

Epoch 00037: val_loss did not improve from 1.40779
Epoch 38/100
199/199 - 12s - loss: 0.4755 - accuracy: 0.9997 - val_loss: 1.3786 - val_accuracy: 0.7672

Epoch 00038: val_loss improved from 1.40779 to 1.37861, saving model to modified_v2_training/cp.ckpt
Epoch 39/100
199/199 - 12s - loss: 0.4555 - accuracy: 0.9998 - val_loss: 1.3728 - val_accuracy: 0.7707

Epoch 00039: val_loss improved from 1.37861 to 1.37276, saving model to modified_v2_training/cp.ckpt
Epoch 40/100
199/199 - 12s - loss: 0.4367 - accuracy: 0.9999 - val_loss: 1.3638 - val_accuracy: 0.7700

Epoch 00040: val_loss improved from 1.37276 to 1.36385, saving model to modified_v2_training/cp.ckpt
Epoch 41/100
199/199 - 12s - loss: 0.4187 - accuracy: 0.9999 - val_loss: 1.3671 - val_accuracy: 0.7665

Epoch 00041: val_loss did not improve from 1.36385
Epoch 42/100
199/199 - 12s - loss: 0.4015 - accuracy: 1.0000 - val_loss: 1.3484 - val_accuracy: 0.7622

Epoch 00042: val_loss improved from 1.36385 to 1.34838, saving model to modified_v2_training/cp.ckpt
Epoch 43/100
199/199 - 12s - loss: 0.3852 - accuracy: 1.0000 - val_loss: 1.3502 - val_accuracy: 0.7657

Epoch 00043: val_loss did not improve from 1.34838
Epoch 44/100
199/199 - 12s - loss: 0.3698 - accuracy: 1.0000 - val_loss: 1.3275 - val_accuracy: 0.7749

Epoch 00044: val_loss improved from 1.34838 to 1.32745, saving model to modified_v2_training/cp.ckpt
Epoch 45/100
199/199 - 12s - loss: 0.3549 - accuracy: 1.0000 - val_loss: 1.3176 - val_accuracy: 0.7757

Epoch 00045: val_loss improved from 1.32745 to 1.31764, saving model to modified_v2_training/cp.ckpt
Epoch 46/100
199/199 - 12s - loss: 0.3406 - accuracy: 1.0000 - val_loss: 1.3022 - val_accuracy: 0.7700

Epoch 00046: val_loss improved from 1.31764 to 1.30222, saving model to modified_v2_training/cp.ckpt
Epoch 47/100
199/199 - 12s - loss: 0.3271 - accuracy: 1.0000 - val_loss: 1.2970 - val_accuracy: 0.7735

Epoch 00047: val_loss improved from 1.30222 to 1.29696, saving model to modified_v2_training/cp.ckpt
Epoch 48/100
199/199 - 12s - loss: 0.3140 - accuracy: 1.0000 - val_loss: 1.2939 - val_accuracy: 0.7693

Epoch 00048: val_loss improved from 1.29696 to 1.29395, saving model to modified_v2_training/cp.ckpt
Epoch 49/100
199/199 - 12s - loss: 0.3016 - accuracy: 1.0000 - val_loss: 1.2905 - val_accuracy: 0.7693

Epoch 00049: val_loss improved from 1.29395 to 1.29053, saving model to modified_v2_training/cp.ckpt
Epoch 50/100
199/199 - 12s - loss: 0.2896 - accuracy: 1.0000 - val_loss: 1.2797 - val_accuracy: 0.7700

Epoch 00050: val_loss improved from 1.29053 to 1.27971, saving model to modified_v2_training/cp.ckpt
Epoch 51/100
199/199 - 12s - loss: 0.2824 - accuracy: 1.0000 - val_loss: 1.2824 - val_accuracy: 0.7735

Epoch 00051: val_loss did not improve from 1.27971
Epoch 52/100
199/199 - 12s - loss: 0.2812 - accuracy: 1.0000 - val_loss: 1.2842 - val_accuracy: 0.7721

Epoch 00052: val_loss did not improve from 1.27971
Epoch 53/100
199/199 - 12s - loss: 0.2801 - accuracy: 1.0000 - val_loss: 1.2835 - val_accuracy: 0.7735

Epoch 00053: val_loss did not improve from 1.27971
Epoch 54/100
199/199 - 12s - loss: 0.2790 - accuracy: 1.0000 - val_loss: 1.2827 - val_accuracy: 0.7742

Epoch 00054: val_loss did not improve from 1.27971
Epoch 55/100
199/199 - 12s - loss: 0.2779 - accuracy: 1.0000 - val_loss: 1.2835 - val_accuracy: 0.7742

Epoch 00055: val_loss did not improve from 1.27971
Epoch 56/100
199/199 - 12s - loss: 0.2767 - accuracy: 1.0000 - val_loss: 1.2827 - val_accuracy: 0.7764

Epoch 00056: val_loss did not improve from 1.27971
Epoch 57/100
199/199 - 12s - loss: 0.2756 - accuracy: 1.0000 - val_loss: 1.2821 - val_accuracy: 0.7742

Epoch 00057: val_loss did not improve from 1.27971
Epoch 58/100
199/199 - 12s - loss: 0.2745 - accuracy: 1.0000 - val_loss: 1.2812 - val_accuracy: 0.7757

Epoch 00058: val_loss did not improve from 1.27971
Epoch 59/100
199/199 - 12s - loss: 0.2734 - accuracy: 1.0000 - val_loss: 1.2812 - val_accuracy: 0.7749

Epoch 00059: val_loss did not improve from 1.27971
Epoch 60/100
199/199 - 12s - loss: 0.2723 - accuracy: 1.0000 - val_loss: 1.2804 - val_accuracy: 0.7721

Epoch 00060: val_loss did not improve from 1.27971
Epoch 61/100
199/199 - 12s - loss: 0.2712 - accuracy: 1.0000 - val_loss: 1.2788 - val_accuracy: 0.7757

Epoch 00061: val_loss improved from 1.27971 to 1.27879, saving model to modified_v2_training/cp.ckpt
Epoch 62/100
199/199 - 12s - loss: 0.2701 - accuracy: 1.0000 - val_loss: 1.2799 - val_accuracy: 0.7742

Epoch 00062: val_loss did not improve from 1.27879
Epoch 63/100
199/199 - 12s - loss: 0.2690 - accuracy: 1.0000 - val_loss: 1.2780 - val_accuracy: 0.7749

Epoch 00063: val_loss improved from 1.27879 to 1.27797, saving model to modified_v2_training/cp.ckpt
Epoch 64/100
199/199 - 12s - loss: 0.2680 - accuracy: 1.0000 - val_loss: 1.2773 - val_accuracy: 0.7757

Epoch 00064: val_loss improved from 1.27797 to 1.27730, saving model to modified_v2_training/cp.ckpt
Epoch 65/100
199/199 - 12s - loss: 0.2669 - accuracy: 1.0000 - val_loss: 1.2756 - val_accuracy: 0.7749

Epoch 00065: val_loss improved from 1.27730 to 1.27558, saving model to modified_v2_training/cp.ckpt
Epoch 66/100
199/199 - 12s - loss: 0.2658 - accuracy: 1.0000 - val_loss: 1.2750 - val_accuracy: 0.7749

Epoch 00066: val_loss improved from 1.27558 to 1.27503, saving model to modified_v2_training/cp.ckpt
Epoch 67/100
199/199 - 12s - loss: 0.2648 - accuracy: 1.0000 - val_loss: 1.2764 - val_accuracy: 0.7749

Epoch 00067: val_loss did not improve from 1.27503
Epoch 68/100
199/199 - 12s - loss: 0.2637 - accuracy: 1.0000 - val_loss: 1.2741 - val_accuracy: 0.7757

Epoch 00068: val_loss improved from 1.27503 to 1.27406, saving model to modified_v2_training/cp.ckpt
Epoch 69/100
199/199 - 12s - loss: 0.2626 - accuracy: 1.0000 - val_loss: 1.2738 - val_accuracy: 0.7757

Epoch 00069: val_loss improved from 1.27406 to 1.27376, saving model to modified_v2_training/cp.ckpt
Epoch 70/100
199/199 - 12s - loss: 0.2616 - accuracy: 1.0000 - val_loss: 1.2728 - val_accuracy: 0.7771

Epoch 00070: val_loss improved from 1.27376 to 1.27281, saving model to modified_v2_training/cp.ckpt
Epoch 71/100
199/199 - 12s - loss: 0.2605 - accuracy: 1.0000 - val_loss: 1.2731 - val_accuracy: 0.7764

Epoch 00071: val_loss did not improve from 1.27281
Epoch 72/100
199/199 - 12s - loss: 0.2595 - accuracy: 1.0000 - val_loss: 1.2719 - val_accuracy: 0.7742

Epoch 00072: val_loss improved from 1.27281 to 1.27193, saving model to modified_v2_training/cp.ckpt
Epoch 73/100
199/199 - 12s - loss: 0.2584 - accuracy: 1.0000 - val_loss: 1.2708 - val_accuracy: 0.7764

Epoch 00073: val_loss improved from 1.27193 to 1.27083, saving model to modified_v2_training/cp.ckpt
Epoch 74/100
199/199 - 12s - loss: 0.2574 - accuracy: 1.0000 - val_loss: 1.2699 - val_accuracy: 0.7757

Epoch 00074: val_loss improved from 1.27083 to 1.26987, saving model to modified_v2_training/cp.ckpt
Epoch 75/100
199/199 - 12s - loss: 0.2564 - accuracy: 1.0000 - val_loss: 1.2711 - val_accuracy: 0.7757

Epoch 00075: val_loss did not improve from 1.26987
Epoch 76/100
199/199 - 12s - loss: 0.2557 - accuracy: 1.0000 - val_loss: 1.2727 - val_accuracy: 0.7764

Epoch 00076: val_loss did not improve from 1.26987
Epoch 77/100
199/199 - 12s - loss: 0.2556 - accuracy: 1.0000 - val_loss: 1.2719 - val_accuracy: 0.7764

Epoch 00077: val_loss did not improve from 1.26987
Epoch 78/100
199/199 - 12s - loss: 0.2555 - accuracy: 1.0000 - val_loss: 1.2705 - val_accuracy: 0.7771

Epoch 00078: val_loss did not improve from 1.26987
Epoch 79/100
199/199 - 12s - loss: 0.2554 - accuracy: 1.0000 - val_loss: 1.2722 - val_accuracy: 0.7771

Epoch 00079: val_loss did not improve from 1.26987
Epoch 80/100
199/199 - 12s - loss: 0.2553 - accuracy: 1.0000 - val_loss: 1.2723 - val_accuracy: 0.7764

Epoch 00080: val_loss did not improve from 1.26987
Epoch 81/100
199/199 - 12s - loss: 0.2552 - accuracy: 1.0000 - val_loss: 1.2725 - val_accuracy: 0.7778

Epoch 00081: val_loss did not improve from 1.26987
Epoch 82/100
199/199 - 12s - loss: 0.2551 - accuracy: 1.0000 - val_loss: 1.2721 - val_accuracy: 0.7757

Epoch 00082: val_loss did not improve from 1.26987
Epoch 83/100
199/199 - 12s - loss: 0.2550 - accuracy: 1.0000 - val_loss: 1.2724 - val_accuracy: 0.7749

Epoch 00083: val_loss did not improve from 1.26987
Epoch 84/100
199/199 - 12s - loss: 0.2549 - accuracy: 1.0000 - val_loss: 1.2714 - val_accuracy: 0.7764

Epoch 00084: val_loss did not improve from 1.26987
Epoch 85/100
199/199 - 12s - loss: 0.2548 - accuracy: 1.0000 - val_loss: 1.2723 - val_accuracy: 0.7764

Epoch 00085: val_loss did not improve from 1.26987
Epoch 86/100
199/199 - 12s - loss: 0.2547 - accuracy: 1.0000 - val_loss: 1.2709 - val_accuracy: 0.7771

Epoch 00086: val_loss did not improve from 1.26987
Epoch 87/100
199/199 - 12s - loss: 0.2546 - accuracy: 1.0000 - val_loss: 1.2712 - val_accuracy: 0.7764

Epoch 00087: val_loss did not improve from 1.26987
Epoch 88/100
199/199 - 12s - loss: 0.2545 - accuracy: 1.0000 - val_loss: 1.2708 - val_accuracy: 0.7757

Epoch 00088: val_loss did not improve from 1.26987
Epoch 89/100
199/199 - 12s - loss: 0.2544 - accuracy: 1.0000 - val_loss: 1.2717 - val_accuracy: 0.7778

Epoch 00089: val_loss did not improve from 1.26987
Epoch 90/100
199/199 - 12s - loss: 0.2543 - accuracy: 1.0000 - val_loss: 1.2729 - val_accuracy: 0.7764

Epoch 00090: val_loss did not improve from 1.26987
Epoch 91/100
199/199 - 12s - loss: 0.2542 - accuracy: 1.0000 - val_loss: 1.2719 - val_accuracy: 0.7771

Epoch 00091: val_loss did not improve from 1.26987
Epoch 92/100
199/199 - 12s - loss: 0.2541 - accuracy: 1.0000 - val_loss: 1.2721 - val_accuracy: 0.7771

Epoch 00092: val_loss did not improve from 1.26987
Epoch 93/100
199/199 - 12s - loss: 0.2540 - accuracy: 1.0000 - val_loss: 1.2702 - val_accuracy: 0.7764

Epoch 00093: val_loss did not improve from 1.26987
Epoch 94/100
199/199 - 12s - loss: 0.2539 - accuracy: 1.0000 - val_loss: 1.2712 - val_accuracy: 0.7757

Epoch 00094: val_loss did not improve from 1.26987
Epoch 95/100
199/199 - 12s - loss: 0.2538 - accuracy: 1.0000 - val_loss: 1.2711 - val_accuracy: 0.7764

Epoch 00095: val_loss did not improve from 1.26987
Epoch 96/100
199/199 - 12s - loss: 0.2537 - accuracy: 1.0000 - val_loss: 1.2717 - val_accuracy: 0.7771

Epoch 00096: val_loss did not improve from 1.26987
Epoch 97/100
199/199 - 12s - loss: 0.2536 - accuracy: 1.0000 - val_loss: 1.2708 - val_accuracy: 0.7757

Epoch 00097: val_loss did not improve from 1.26987
Epoch 98/100
199/199 - 12s - loss: 0.2535 - accuracy: 1.0000 - val_loss: 1.2712 - val_accuracy: 0.7764

Epoch 00098: val_loss did not improve from 1.26987
Epoch 99/100
199/199 - 12s - loss: 0.2534 - accuracy: 1.0000 - val_loss: 1.2716 - val_accuracy: 0.7778

Epoch 00099: val_loss did not improve from 1.26987
Epoch 100/100
199/199 - 12s - loss: 0.2533 - accuracy: 1.0000 - val_loss: 1.2704 - val_accuracy: 0.7764

Epoch 00100: val_loss did not improve from 1.26987
Total time taken to train in seconds: 1810.5176301002502
Model: "model_1"
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            [(None, 224, 224, 3) 0                                            
__________________________________________________________________________________________________
conv1 (Conv2D)                  (None, 112, 112, 64) 4864        input_2[0][0]                    
__________________________________________________________________________________________________
batch_normalization_33 (BatchNo (None, 112, 112, 64) 256         conv1[0][0]                      
__________________________________________________________________________________________________
activation_37 (Activation)      (None, 112, 112, 64) 0           batch_normalization_33[0][0]     
__________________________________________________________________________________________________
pool1 (MaxPooling2D)            (None, 55, 55, 64)   0           activation_37[0][0]              
__________________________________________________________________________________________________
nu_inception_1_3x3_reduce (Conv (None, 55, 55, 24)   1560        pool1[0][0]                      
__________________________________________________________________________________________________
nu_inception_1_5x5_reduce (Conv (None, 55, 55, 4)    260         pool1[0][0]                      
__________________________________________________________________________________________________
batch_normalization_35 (BatchNo (None, 55, 55, 24)   96          nu_inception_1_3x3_reduce[0][0]  
__________________________________________________________________________________________________
batch_normalization_37 (BatchNo (None, 55, 55, 4)    16          nu_inception_1_5x5_reduce[0][0]  
__________________________________________________________________________________________________
activation_39 (Activation)      (None, 55, 55, 24)   0           batch_normalization_35[0][0]     
__________________________________________________________________________________________________
activation_41 (Activation)      (None, 55, 55, 4)    0           batch_normalization_37[0][0]     
__________________________________________________________________________________________________
nu_inception_1_maxpool (MaxPool (None, 55, 55, 64)   0           pool1[0][0]                      
__________________________________________________________________________________________________
nu_inception_1_1x1 (Conv2D)     (None, 55, 55, 16)   1040        pool1[0][0]                      
__________________________________________________________________________________________________
nu_inception_1_3x3 (Conv2D)     (None, 55, 55, 32)   6944        activation_39[0][0]              
__________________________________________________________________________________________________
nu_inception_1_5x5 (Conv2D)     (None, 55, 55, 8)    296         activation_41[0][0]              
__________________________________________________________________________________________________
nu_inception_1_1x1_0 (Conv2D)   (None, 55, 55, 8)    520         nu_inception_1_maxpool[0][0]     
__________________________________________________________________________________________________
batch_normalization_34 (BatchNo (None, 55, 55, 16)   64          nu_inception_1_1x1[0][0]         
__________________________________________________________________________________________________
batch_normalization_36 (BatchNo (None, 55, 55, 32)   128         nu_inception_1_3x3[0][0]         
__________________________________________________________________________________________________
batch_normalization_38 (BatchNo (None, 55, 55, 8)    32          nu_inception_1_5x5[0][0]         
__________________________________________________________________________________________________
batch_normalization_39 (BatchNo (None, 55, 55, 8)    32          nu_inception_1_1x1_0[0][0]       
__________________________________________________________________________________________________
activation_38 (Activation)      (None, 55, 55, 16)   0           batch_normalization_34[0][0]     
__________________________________________________________________________________________________
activation_40 (Activation)      (None, 55, 55, 32)   0           batch_normalization_36[0][0]     
__________________________________________________________________________________________________
activation_42 (Activation)      (None, 55, 55, 8)    0           batch_normalization_38[0][0]     
__________________________________________________________________________________________________
activation_43 (Activation)      (None, 55, 55, 8)    0           batch_normalization_39[0][0]     
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 55, 55, 64)   0           activation_38[0][0]              
                                                                 activation_40[0][0]              
                                                                 activation_42[0][0]              
                                                                 activation_43[0][0]              
__________________________________________________________________________________________________
conv_direct_1 (Conv2D)          (None, 55, 55, 64)   4160        concatenate_4[0][0]              
__________________________________________________________________________________________________
conv_bypass_1 (Conv2D)          (None, 55, 55, 64)   4160        pool1[0][0]                      
__________________________________________________________________________________________________
batch_normalization_40 (BatchNo (None, 55, 55, 64)   256         conv_direct_1[0][0]              
__________________________________________________________________________________________________
batch_normalization_41 (BatchNo (None, 55, 55, 64)   256         conv_bypass_1[0][0]              
__________________________________________________________________________________________________
activation_44 (Activation)      (None, 55, 55, 64)   0           batch_normalization_40[0][0]     
__________________________________________________________________________________________________
activation_45 (Activation)      (None, 55, 55, 64)   0           batch_normalization_41[0][0]     
__________________________________________________________________________________________________
residual1 (Add)                 (None, 55, 55, 64)   0           activation_44[0][0]              
                                                                 activation_45[0][0]              
__________________________________________________________________________________________________
activation_46 (Activation)      (None, 55, 55, 64)   0           residual1[0][0]                  
__________________________________________________________________________________________________
pool2 (MaxPooling2D)            (None, 27, 27, 64)   0           activation_46[0][0]              
__________________________________________________________________________________________________
nu_inception_2_3x3_reduce (Conv (None, 27, 27, 48)   3120        pool2[0][0]                      
__________________________________________________________________________________________________
nu_inception_2_5x5_reduce (Conv (None, 27, 27, 8)    520         pool2[0][0]                      
__________________________________________________________________________________________________
batch_normalization_43 (BatchNo (None, 27, 27, 48)   192         nu_inception_2_3x3_reduce[0][0]  
__________________________________________________________________________________________________
batch_normalization_45 (BatchNo (None, 27, 27, 8)    32          nu_inception_2_5x5_reduce[0][0]  
__________________________________________________________________________________________________
activation_48 (Activation)      (None, 27, 27, 48)   0           batch_normalization_43[0][0]     
__________________________________________________________________________________________________
activation_50 (Activation)      (None, 27, 27, 8)    0           batch_normalization_45[0][0]     
__________________________________________________________________________________________________
nu_inception_2_maxpool (MaxPool (None, 27, 27, 64)   0           pool2[0][0]                      
__________________________________________________________________________________________________
nu_inception_2_1x1 (Conv2D)     (None, 27, 27, 32)   2080        pool2[0][0]                      
__________________________________________________________________________________________________
nu_inception_2_3x3 (Conv2D)     (None, 27, 27, 64)   27712       activation_48[0][0]              
__________________________________________________________________________________________________
nu_inception_2_5x5 (Conv2D)     (None, 27, 27, 16)   1168        activation_50[0][0]              
__________________________________________________________________________________________________
nu_inception_2_1x1_0 (Conv2D)   (None, 27, 27, 16)   1040        nu_inception_2_maxpool[0][0]     
__________________________________________________________________________________________________
batch_normalization_42 (BatchNo (None, 27, 27, 32)   128         nu_inception_2_1x1[0][0]         
__________________________________________________________________________________________________
batch_normalization_44 (BatchNo (None, 27, 27, 64)   256         nu_inception_2_3x3[0][0]         
__________________________________________________________________________________________________
batch_normalization_46 (BatchNo (None, 27, 27, 16)   64          nu_inception_2_5x5[0][0]         
__________________________________________________________________________________________________
batch_normalization_47 (BatchNo (None, 27, 27, 16)   64          nu_inception_2_1x1_0[0][0]       
__________________________________________________________________________________________________
activation_47 (Activation)      (None, 27, 27, 32)   0           batch_normalization_42[0][0]     
__________________________________________________________________________________________________
activation_49 (Activation)      (None, 27, 27, 64)   0           batch_normalization_44[0][0]     
__________________________________________________________________________________________________
activation_51 (Activation)      (None, 27, 27, 16)   0           batch_normalization_46[0][0]     
__________________________________________________________________________________________________
activation_52 (Activation)      (None, 27, 27, 16)   0           batch_normalization_47[0][0]     
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 27, 27, 128)  0           activation_47[0][0]              
                                                                 activation_49[0][0]              
                                                                 activation_51[0][0]              
                                                                 activation_52[0][0]              
__________________________________________________________________________________________________
conv_direct_2 (Conv2D)          (None, 27, 27, 128)  16512       concatenate_5[0][0]              
__________________________________________________________________________________________________
conv_bypass_2 (Conv2D)          (None, 27, 27, 128)  8320        pool2[0][0]                      
__________________________________________________________________________________________________
batch_normalization_48 (BatchNo (None, 27, 27, 128)  512         conv_direct_2[0][0]              
__________________________________________________________________________________________________
batch_normalization_49 (BatchNo (None, 27, 27, 128)  512         conv_bypass_2[0][0]              
__________________________________________________________________________________________________
activation_53 (Activation)      (None, 27, 27, 128)  0           batch_normalization_48[0][0]     
__________________________________________________________________________________________________
activation_54 (Activation)      (None, 27, 27, 128)  0           batch_normalization_49[0][0]     
__________________________________________________________________________________________________
residual2 (Add)                 (None, 27, 27, 128)  0           activation_53[0][0]              
                                                                 activation_54[0][0]              
__________________________________________________________________________________________________
activation_55 (Activation)      (None, 27, 27, 128)  0           residual2[0][0]                  
__________________________________________________________________________________________________
pool3 (MaxPooling2D)            (None, 13, 13, 128)  0           activation_55[0][0]              
__________________________________________________________________________________________________
nu_inception_3_3x3_reduce (Conv (None, 13, 13, 96)   12384       pool3[0][0]                      
__________________________________________________________________________________________________
nu_inception_3_5x5_reduce (Conv (None, 13, 13, 16)   2064        pool3[0][0]                      
__________________________________________________________________________________________________
batch_normalization_51 (BatchNo (None, 13, 13, 96)   384         nu_inception_3_3x3_reduce[0][0]  
__________________________________________________________________________________________________
batch_normalization_53 (BatchNo (None, 13, 13, 16)   64          nu_inception_3_5x5_reduce[0][0]  
__________________________________________________________________________________________________
activation_57 (Activation)      (None, 13, 13, 96)   0           batch_normalization_51[0][0]     
__________________________________________________________________________________________________
activation_59 (Activation)      (None, 13, 13, 16)   0           batch_normalization_53[0][0]     
__________________________________________________________________________________________________
nu_inception_3_maxpool (MaxPool (None, 13, 13, 128)  0           pool3[0][0]                      
__________________________________________________________________________________________________
nu_inception_3_1x1 (Conv2D)     (None, 13, 13, 64)   8256        pool3[0][0]                      
__________________________________________________________________________________________________
nu_inception_3_3x3 (Conv2D)     (None, 13, 13, 128)  110720      activation_57[0][0]              
__________________________________________________________________________________________________
nu_inception_3_5x5 (Conv2D)     (None, 13, 13, 32)   4640        activation_59[0][0]              
__________________________________________________________________________________________________
nu_inception_3_1x1_0 (Conv2D)   (None, 13, 13, 32)   4128        nu_inception_3_maxpool[0][0]     
__________________________________________________________________________________________________
batch_normalization_50 (BatchNo (None, 13, 13, 64)   256         nu_inception_3_1x1[0][0]         
__________________________________________________________________________________________________
batch_normalization_52 (BatchNo (None, 13, 13, 128)  512         nu_inception_3_3x3[0][0]         
__________________________________________________________________________________________________
batch_normalization_54 (BatchNo (None, 13, 13, 32)   128         nu_inception_3_5x5[0][0]         
__________________________________________________________________________________________________
batch_normalization_55 (BatchNo (None, 13, 13, 32)   128         nu_inception_3_1x1_0[0][0]       
__________________________________________________________________________________________________
activation_56 (Activation)      (None, 13, 13, 64)   0           batch_normalization_50[0][0]     
__________________________________________________________________________________________________
activation_58 (Activation)      (None, 13, 13, 128)  0           batch_normalization_52[0][0]     
__________________________________________________________________________________________________
activation_60 (Activation)      (None, 13, 13, 32)   0           batch_normalization_54[0][0]     
__________________________________________________________________________________________________
activation_61 (Activation)      (None, 13, 13, 32)   0           batch_normalization_55[0][0]     
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 13, 13, 256)  0           activation_56[0][0]              
                                                                 activation_58[0][0]              
                                                                 activation_60[0][0]              
                                                                 activation_61[0][0]              
__________________________________________________________________________________________________
conv_direct_3 (Conv2D)          (None, 13, 13, 256)  65792       concatenate_6[0][0]              
__________________________________________________________________________________________________
conv_bypass_3 (Conv2D)          (None, 13, 13, 256)  33024       pool3[0][0]                      
__________________________________________________________________________________________________
batch_normalization_56 (BatchNo (None, 13, 13, 256)  1024        conv_direct_3[0][0]              
__________________________________________________________________________________________________
batch_normalization_57 (BatchNo (None, 13, 13, 256)  1024        conv_bypass_3[0][0]              
__________________________________________________________________________________________________
activation_62 (Activation)      (None, 13, 13, 256)  0           batch_normalization_56[0][0]     
__________________________________________________________________________________________________
activation_63 (Activation)      (None, 13, 13, 256)  0           batch_normalization_57[0][0]     
__________________________________________________________________________________________________
residual3 (Add)                 (None, 13, 13, 256)  0           activation_62[0][0]              
                                                                 activation_63[0][0]              
__________________________________________________________________________________________________
activation_64 (Activation)      (None, 13, 13, 256)  0           residual3[0][0]                  
__________________________________________________________________________________________________
pool4 (MaxPooling2D)            (None, 6, 6, 256)    0           activation_64[0][0]              
__________________________________________________________________________________________________
nu_inception_4_3x3_reduce (Conv (None, 6, 6, 192)    49344       pool4[0][0]                      
__________________________________________________________________________________________________
nu_inception_4_5x5_reduce (Conv (None, 6, 6, 32)     8224        pool4[0][0]                      
__________________________________________________________________________________________________
batch_normalization_59 (BatchNo (None, 6, 6, 192)    768         nu_inception_4_3x3_reduce[0][0]  
__________________________________________________________________________________________________
batch_normalization_61 (BatchNo (None, 6, 6, 32)     128         nu_inception_4_5x5_reduce[0][0]  
__________________________________________________________________________________________________
activation_66 (Activation)      (None, 6, 6, 192)    0           batch_normalization_59[0][0]     
__________________________________________________________________________________________________
activation_68 (Activation)      (None, 6, 6, 32)     0           batch_normalization_61[0][0]     
__________________________________________________________________________________________________
nu_inception_4_maxpool (MaxPool (None, 6, 6, 256)    0           pool4[0][0]                      
__________________________________________________________________________________________________
nu_inception_4_1x1 (Conv2D)     (None, 6, 6, 128)    32896       pool4[0][0]                      
__________________________________________________________________________________________________
nu_inception_4_3x3 (Conv2D)     (None, 6, 6, 256)    442624      activation_66[0][0]              
__________________________________________________________________________________________________
nu_inception_4_5x5 (Conv2D)     (None, 6, 6, 64)     18496       activation_68[0][0]              
__________________________________________________________________________________________________
nu_inception_4_1x1_0 (Conv2D)   (None, 6, 6, 64)     16448       nu_inception_4_maxpool[0][0]     
__________________________________________________________________________________________________
batch_normalization_58 (BatchNo (None, 6, 6, 128)    512         nu_inception_4_1x1[0][0]         
__________________________________________________________________________________________________
batch_normalization_60 (BatchNo (None, 6, 6, 256)    1024        nu_inception_4_3x3[0][0]         
__________________________________________________________________________________________________
batch_normalization_62 (BatchNo (None, 6, 6, 64)     256         nu_inception_4_5x5[0][0]         
__________________________________________________________________________________________________
batch_normalization_63 (BatchNo (None, 6, 6, 64)     256         nu_inception_4_1x1_0[0][0]       
__________________________________________________________________________________________________
activation_65 (Activation)      (None, 6, 6, 128)    0           batch_normalization_58[0][0]     
__________________________________________________________________________________________________
activation_67 (Activation)      (None, 6, 6, 256)    0           batch_normalization_60[0][0]     
__________________________________________________________________________________________________
activation_69 (Activation)      (None, 6, 6, 64)     0           batch_normalization_62[0][0]     
__________________________________________________________________________________________________
activation_70 (Activation)      (None, 6, 6, 64)     0           batch_normalization_63[0][0]     
__________________________________________________________________________________________________
concatenate_7 (Concatenate)     (None, 6, 6, 512)    0           activation_65[0][0]              
                                                                 activation_67[0][0]              
                                                                 activation_69[0][0]              
                                                                 activation_70[0][0]              
__________________________________________________________________________________________________
conv_direct_4 (Conv2D)          (None, 6, 6, 512)    262656      concatenate_7[0][0]              
__________________________________________________________________________________________________
conv_bypass_4 (Conv2D)          (None, 6, 6, 512)    131584      pool4[0][0]                      
__________________________________________________________________________________________________
batch_normalization_64 (BatchNo (None, 6, 6, 512)    2048        conv_direct_4[0][0]              
__________________________________________________________________________________________________
batch_normalization_65 (BatchNo (None, 6, 6, 512)    2048        conv_bypass_4[0][0]              
__________________________________________________________________________________________________
activation_71 (Activation)      (None, 6, 6, 512)    0           batch_normalization_64[0][0]     
__________________________________________________________________________________________________
activation_72 (Activation)      (None, 6, 6, 512)    0           batch_normalization_65[0][0]     
__________________________________________________________________________________________________
residual4 (Add)                 (None, 6, 6, 512)    0           activation_71[0][0]              
                                                                 activation_72[0][0]              
__________________________________________________________________________________________________
activation_73 (Activation)      (None, 6, 6, 512)    0           residual4[0][0]                  
__________________________________________________________________________________________________
avg_pool (GlobalAveragePooling2 (None, 512)          0           activation_73[0][0]              
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 50)           25650       avg_pool[0][0]                   
==================================================================================================
Total params: 1,326,662
Trainable params: 1,319,934
Non-trainable params: 6,728
__________________________________________________________________________________________________
 1/25 [>.............................] - ETA: 1:29 - loss: 1.3472 - accuracy: 0.7188 2/25 [=>............................] - ETA: 9s - loss: 1.1657 - accuracy: 0.7656   3/25 [==>...........................] - ETA: 8s - loss: 1.0710 - accuracy: 0.7760 4/25 [===>..........................] - ETA: 7s - loss: 1.0884 - accuracy: 0.7773 5/25 [=====>........................] - ETA: 6s - loss: 1.0989 - accuracy: 0.7781 6/25 [======>.......................] - ETA: 6s - loss: 1.1522 - accuracy: 0.7708 7/25 [=======>......................] - ETA: 6s - loss: 1.1479 - accuracy: 0.7746 8/25 [========>.....................] - ETA: 5s - loss: 1.1332 - accuracy: 0.7754 9/25 [=========>....................] - ETA: 5s - loss: 1.1923 - accuracy: 0.774310/25 [===========>..................] - ETA: 5s - loss: 1.1962 - accuracy: 0.775011/25 [============>.................] - ETA: 4s - loss: 1.2018 - accuracy: 0.778412/25 [=============>................] - ETA: 4s - loss: 1.1879 - accuracy: 0.776013/25 [==============>...............] - ETA: 3s - loss: 1.2199 - accuracy: 0.771614/25 [===============>..............] - ETA: 3s - loss: 1.1937 - accuracy: 0.776815/25 [=================>............] - ETA: 3s - loss: 1.1783 - accuracy: 0.779216/25 [==================>...........] - ETA: 2s - loss: 1.1709 - accuracy: 0.779317/25 [===================>..........] - ETA: 2s - loss: 1.1822 - accuracy: 0.780318/25 [====================>.........] - ETA: 2s - loss: 1.1678 - accuracy: 0.782120/25 [=======================>......] - ETA: 1s - loss: 1.1753 - accuracy: 0.780522/25 [=========================>....] - ETA: 0s - loss: 1.1719 - accuracy: 0.781224/25 [===========================>..] - ETA: 0s - loss: 1.1677 - accuracy: 0.782625/25 [==============================] - ETA: 0s - loss: 1.1610 - accuracy: 0.784625/25 [==============================] - 10s 241ms/step - loss: 1.1610 - accuracy: 0.7846
