Found 12720 files belonging to 50 classes.
Found 1413 files belonging to 50 classes.
Found 1597 files belonging to 50 classes.
Model: "model"
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            [(None, 224, 224, 3) 0                                            
__________________________________________________________________________________________________
conv1 (Conv2D)                  (None, 112, 112, 64) 4864        input_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization (BatchNorma (None, 112, 112, 64) 256         conv1[0][0]                      
__________________________________________________________________________________________________
activation (Activation)         (None, 112, 112, 64) 0           batch_normalization[0][0]        
__________________________________________________________________________________________________
pool1 (MaxPooling2D)            (None, 55, 55, 64)   0           activation[0][0]                 
__________________________________________________________________________________________________
nu_inception_1_3x3_1_3 (Conv2D) (None, 55, 55, 8)    4616        pool1[0][0]                      
__________________________________________________________________________________________________
batch_normalization_5 (BatchNor (None, 55, 55, 8)    32          nu_inception_1_3x3_1_3[0][0]     
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 55, 55, 8)    0           batch_normalization_5[0][0]      
__________________________________________________________________________________________________
nu_inception_1_3x3_1 (Conv2D)   (None, 55, 55, 8)    4616        pool1[0][0]                      
__________________________________________________________________________________________________
nu_inception_1_3x3_2_3 (Conv2D) (None, 55, 55, 8)    584         activation_5[0][0]               
__________________________________________________________________________________________________
batch_normalization_3 (BatchNor (None, 55, 55, 8)    32          nu_inception_1_3x3_1[0][0]       
__________________________________________________________________________________________________
batch_normalization_6 (BatchNor (None, 55, 55, 8)    32          nu_inception_1_3x3_2_3[0][0]     
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 55, 55, 8)    0           batch_normalization_3[0][0]      
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 55, 55, 8)    0           batch_normalization_6[0][0]      
__________________________________________________________________________________________________
nu_inception_1_1x1 (Conv2D)     (None, 55, 55, 16)   1040        pool1[0][0]                      
__________________________________________________________________________________________________
nu_inception_1_3x3 (Conv2D)     (None, 55, 55, 32)   18464       pool1[0][0]                      
__________________________________________________________________________________________________
nu_inception_1_3x3_2 (Conv2D)   (None, 55, 55, 8)    584         activation_3[0][0]               
__________________________________________________________________________________________________
nu_inception_1_3x3_3_3 (Conv2D) (None, 55, 55, 8)    584         activation_6[0][0]               
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 55, 55, 16)   64          nu_inception_1_1x1[0][0]         
__________________________________________________________________________________________________
batch_normalization_2 (BatchNor (None, 55, 55, 32)   128         nu_inception_1_3x3[0][0]         
__________________________________________________________________________________________________
batch_normalization_4 (BatchNor (None, 55, 55, 8)    32          nu_inception_1_3x3_2[0][0]       
__________________________________________________________________________________________________
batch_normalization_7 (BatchNor (None, 55, 55, 8)    32          nu_inception_1_3x3_3_3[0][0]     
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 55, 55, 16)   0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 55, 55, 32)   0           batch_normalization_2[0][0]      
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 55, 55, 8)    0           batch_normalization_4[0][0]      
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 55, 55, 8)    0           batch_normalization_7[0][0]      
__________________________________________________________________________________________________
concatenate (Concatenate)       (None, 55, 55, 64)   0           activation_1[0][0]               
                                                                 activation_2[0][0]               
                                                                 activation_4[0][0]               
                                                                 activation_7[0][0]               
__________________________________________________________________________________________________
conv_direct_1 (Conv2D)          (None, 55, 55, 64)   4160        concatenate[0][0]                
__________________________________________________________________________________________________
conv_bypass_1 (Conv2D)          (None, 55, 55, 64)   4160        pool1[0][0]                      
__________________________________________________________________________________________________
batch_normalization_8 (BatchNor (None, 55, 55, 64)   256         conv_direct_1[0][0]              
__________________________________________________________________________________________________
batch_normalization_9 (BatchNor (None, 55, 55, 64)   256         conv_bypass_1[0][0]              
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 55, 55, 64)   0           batch_normalization_8[0][0]      
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 55, 55, 64)   0           batch_normalization_9[0][0]      
__________________________________________________________________________________________________
residual1 (Add)                 (None, 55, 55, 64)   0           activation_8[0][0]               
                                                                 activation_9[0][0]               
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 55, 55, 64)   0           residual1[0][0]                  
__________________________________________________________________________________________________
pool2 (MaxPooling2D)            (None, 27, 27, 64)   0           activation_10[0][0]              
__________________________________________________________________________________________________
nu_inception_2_3x3_1_3 (Conv2D) (None, 27, 27, 16)   9232        pool2[0][0]                      
__________________________________________________________________________________________________
batch_normalization_14 (BatchNo (None, 27, 27, 16)   64          nu_inception_2_3x3_1_3[0][0]     
__________________________________________________________________________________________________
activation_15 (Activation)      (None, 27, 27, 16)   0           batch_normalization_14[0][0]     
__________________________________________________________________________________________________
nu_inception_2_3x3_1 (Conv2D)   (None, 27, 27, 16)   9232        pool2[0][0]                      
__________________________________________________________________________________________________
nu_inception_2_3x3_2_3 (Conv2D) (None, 27, 27, 16)   2320        activation_15[0][0]              
__________________________________________________________________________________________________
batch_normalization_12 (BatchNo (None, 27, 27, 16)   64          nu_inception_2_3x3_1[0][0]       
__________________________________________________________________________________________________
batch_normalization_15 (BatchNo (None, 27, 27, 16)   64          nu_inception_2_3x3_2_3[0][0]     
__________________________________________________________________________________________________
activation_13 (Activation)      (None, 27, 27, 16)   0           batch_normalization_12[0][0]     
__________________________________________________________________________________________________
activation_16 (Activation)      (None, 27, 27, 16)   0           batch_normalization_15[0][0]     
__________________________________________________________________________________________________
nu_inception_2_1x1 (Conv2D)     (None, 27, 27, 32)   2080        pool2[0][0]                      
__________________________________________________________________________________________________
nu_inception_2_3x3 (Conv2D)     (None, 27, 27, 64)   36928       pool2[0][0]                      
__________________________________________________________________________________________________
nu_inception_2_3x3_2 (Conv2D)   (None, 27, 27, 16)   2320        activation_13[0][0]              
__________________________________________________________________________________________________
nu_inception_2_3x3_3_3 (Conv2D) (None, 27, 27, 16)   2320        activation_16[0][0]              
__________________________________________________________________________________________________
batch_normalization_10 (BatchNo (None, 27, 27, 32)   128         nu_inception_2_1x1[0][0]         
__________________________________________________________________________________________________
batch_normalization_11 (BatchNo (None, 27, 27, 64)   256         nu_inception_2_3x3[0][0]         
__________________________________________________________________________________________________
batch_normalization_13 (BatchNo (None, 27, 27, 16)   64          nu_inception_2_3x3_2[0][0]       
__________________________________________________________________________________________________
batch_normalization_16 (BatchNo (None, 27, 27, 16)   64          nu_inception_2_3x3_3_3[0][0]     
__________________________________________________________________________________________________
activation_11 (Activation)      (None, 27, 27, 32)   0           batch_normalization_10[0][0]     
__________________________________________________________________________________________________
activation_12 (Activation)      (None, 27, 27, 64)   0           batch_normalization_11[0][0]     
__________________________________________________________________________________________________
activation_14 (Activation)      (None, 27, 27, 16)   0           batch_normalization_13[0][0]     
__________________________________________________________________________________________________
activation_17 (Activation)      (None, 27, 27, 16)   0           batch_normalization_16[0][0]     
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 27, 27, 128)  0           activation_11[0][0]              
                                                                 activation_12[0][0]              
                                                                 activation_14[0][0]              
                                                                 activation_17[0][0]              
__________________________________________________________________________________________________
conv_direct_2 (Conv2D)          (None, 27, 27, 128)  16512       concatenate_1[0][0]              
__________________________________________________________________________________________________
conv_bypass_2 (Conv2D)          (None, 27, 27, 128)  8320        pool2[0][0]                      
__________________________________________________________________________________________________
batch_normalization_17 (BatchNo (None, 27, 27, 128)  512         conv_direct_2[0][0]              
__________________________________________________________________________________________________
batch_normalization_18 (BatchNo (None, 27, 27, 128)  512         conv_bypass_2[0][0]              
__________________________________________________________________________________________________
activation_18 (Activation)      (None, 27, 27, 128)  0           batch_normalization_17[0][0]     
__________________________________________________________________________________________________
activation_19 (Activation)      (None, 27, 27, 128)  0           batch_normalization_18[0][0]     
__________________________________________________________________________________________________
residual2 (Add)                 (None, 27, 27, 128)  0           activation_18[0][0]              
                                                                 activation_19[0][0]              
__________________________________________________________________________________________________
activation_20 (Activation)      (None, 27, 27, 128)  0           residual2[0][0]                  
__________________________________________________________________________________________________
pool3 (MaxPooling2D)            (None, 13, 13, 128)  0           activation_20[0][0]              
__________________________________________________________________________________________________
nu_inception_3_3x3_1_3 (Conv2D) (None, 13, 13, 32)   36896       pool3[0][0]                      
__________________________________________________________________________________________________
batch_normalization_23 (BatchNo (None, 13, 13, 32)   128         nu_inception_3_3x3_1_3[0][0]     
__________________________________________________________________________________________________
activation_25 (Activation)      (None, 13, 13, 32)   0           batch_normalization_23[0][0]     
__________________________________________________________________________________________________
nu_inception_3_3x3_1 (Conv2D)   (None, 13, 13, 32)   36896       pool3[0][0]                      
__________________________________________________________________________________________________
nu_inception_3_3x3_2_3 (Conv2D) (None, 13, 13, 32)   9248        activation_25[0][0]              
__________________________________________________________________________________________________
batch_normalization_21 (BatchNo (None, 13, 13, 32)   128         nu_inception_3_3x3_1[0][0]       
__________________________________________________________________________________________________
batch_normalization_24 (BatchNo (None, 13, 13, 32)   128         nu_inception_3_3x3_2_3[0][0]     
__________________________________________________________________________________________________
activation_23 (Activation)      (None, 13, 13, 32)   0           batch_normalization_21[0][0]     
__________________________________________________________________________________________________
activation_26 (Activation)      (None, 13, 13, 32)   0           batch_normalization_24[0][0]     
__________________________________________________________________________________________________
nu_inception_3_1x1 (Conv2D)     (None, 13, 13, 64)   8256        pool3[0][0]                      
__________________________________________________________________________________________________
nu_inception_3_3x3 (Conv2D)     (None, 13, 13, 128)  147584      pool3[0][0]                      
__________________________________________________________________________________________________
nu_inception_3_3x3_2 (Conv2D)   (None, 13, 13, 32)   9248        activation_23[0][0]              
__________________________________________________________________________________________________
nu_inception_3_3x3_3_3 (Conv2D) (None, 13, 13, 32)   9248        activation_26[0][0]              
__________________________________________________________________________________________________
batch_normalization_19 (BatchNo (None, 13, 13, 64)   256         nu_inception_3_1x1[0][0]         
__________________________________________________________________________________________________
batch_normalization_20 (BatchNo (None, 13, 13, 128)  512         nu_inception_3_3x3[0][0]         
__________________________________________________________________________________________________
batch_normalization_22 (BatchNo (None, 13, 13, 32)   128         nu_inception_3_3x3_2[0][0]       
__________________________________________________________________________________________________
batch_normalization_25 (BatchNo (None, 13, 13, 32)   128         nu_inception_3_3x3_3_3[0][0]     
__________________________________________________________________________________________________
activation_21 (Activation)      (None, 13, 13, 64)   0           batch_normalization_19[0][0]     
__________________________________________________________________________________________________
activation_22 (Activation)      (None, 13, 13, 128)  0           batch_normalization_20[0][0]     
__________________________________________________________________________________________________
activation_24 (Activation)      (None, 13, 13, 32)   0           batch_normalization_22[0][0]     
__________________________________________________________________________________________________
activation_27 (Activation)      (None, 13, 13, 32)   0           batch_normalization_25[0][0]     
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 13, 13, 256)  0           activation_21[0][0]              
                                                                 activation_22[0][0]              
                                                                 activation_24[0][0]              
                                                                 activation_27[0][0]              
__________________________________________________________________________________________________
conv_direct_3 (Conv2D)          (None, 13, 13, 256)  65792       concatenate_2[0][0]              
__________________________________________________________________________________________________
conv_bypass_3 (Conv2D)          (None, 13, 13, 256)  33024       pool3[0][0]                      
__________________________________________________________________________________________________
batch_normalization_26 (BatchNo (None, 13, 13, 256)  1024        conv_direct_3[0][0]              
__________________________________________________________________________________________________
batch_normalization_27 (BatchNo (None, 13, 13, 256)  1024        conv_bypass_3[0][0]              
__________________________________________________________________________________________________
activation_28 (Activation)      (None, 13, 13, 256)  0           batch_normalization_26[0][0]     
__________________________________________________________________________________________________
activation_29 (Activation)      (None, 13, 13, 256)  0           batch_normalization_27[0][0]     
__________________________________________________________________________________________________
residual3 (Add)                 (None, 13, 13, 256)  0           activation_28[0][0]              
                                                                 activation_29[0][0]              
__________________________________________________________________________________________________
activation_30 (Activation)      (None, 13, 13, 256)  0           residual3[0][0]                  
__________________________________________________________________________________________________
pool4 (MaxPooling2D)            (None, 6, 6, 256)    0           activation_30[0][0]              
__________________________________________________________________________________________________
nu_inception_4_3x3_1_3 (Conv2D) (None, 6, 6, 64)     147520      pool4[0][0]                      
__________________________________________________________________________________________________
batch_normalization_32 (BatchNo (None, 6, 6, 64)     256         nu_inception_4_3x3_1_3[0][0]     
__________________________________________________________________________________________________
activation_35 (Activation)      (None, 6, 6, 64)     0           batch_normalization_32[0][0]     
__________________________________________________________________________________________________
nu_inception_4_3x3_1 (Conv2D)   (None, 6, 6, 64)     147520      pool4[0][0]                      
__________________________________________________________________________________________________
nu_inception_4_3x3_2_3 (Conv2D) (None, 6, 6, 64)     36928       activation_35[0][0]              
__________________________________________________________________________________________________
batch_normalization_30 (BatchNo (None, 6, 6, 64)     256         nu_inception_4_3x3_1[0][0]       
__________________________________________________________________________________________________
batch_normalization_33 (BatchNo (None, 6, 6, 64)     256         nu_inception_4_3x3_2_3[0][0]     
__________________________________________________________________________________________________
activation_33 (Activation)      (None, 6, 6, 64)     0           batch_normalization_30[0][0]     
__________________________________________________________________________________________________
activation_36 (Activation)      (None, 6, 6, 64)     0           batch_normalization_33[0][0]     
__________________________________________________________________________________________________
nu_inception_4_1x1 (Conv2D)     (None, 6, 6, 128)    32896       pool4[0][0]                      
__________________________________________________________________________________________________
nu_inception_4_3x3 (Conv2D)     (None, 6, 6, 256)    590080      pool4[0][0]                      
__________________________________________________________________________________________________
nu_inception_4_3x3_2 (Conv2D)   (None, 6, 6, 64)     36928       activation_33[0][0]              
__________________________________________________________________________________________________
nu_inception_4_3x3_3_3 (Conv2D) (None, 6, 6, 64)     36928       activation_36[0][0]              
__________________________________________________________________________________________________
batch_normalization_28 (BatchNo (None, 6, 6, 128)    512         nu_inception_4_1x1[0][0]         
__________________________________________________________________________________________________
batch_normalization_29 (BatchNo (None, 6, 6, 256)    1024        nu_inception_4_3x3[0][0]         
__________________________________________________________________________________________________
batch_normalization_31 (BatchNo (None, 6, 6, 64)     256         nu_inception_4_3x3_2[0][0]       
__________________________________________________________________________________________________
batch_normalization_34 (BatchNo (None, 6, 6, 64)     256         nu_inception_4_3x3_3_3[0][0]     
__________________________________________________________________________________________________
activation_31 (Activation)      (None, 6, 6, 128)    0           batch_normalization_28[0][0]     
__________________________________________________________________________________________________
activation_32 (Activation)      (None, 6, 6, 256)    0           batch_normalization_29[0][0]     
__________________________________________________________________________________________________
activation_34 (Activation)      (None, 6, 6, 64)     0           batch_normalization_31[0][0]     
__________________________________________________________________________________________________
activation_37 (Activation)      (None, 6, 6, 64)     0           batch_normalization_34[0][0]     
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 6, 6, 512)    0           activation_31[0][0]              
                                                                 activation_32[0][0]              
                                                                 activation_34[0][0]              
                                                                 activation_37[0][0]              
__________________________________________________________________________________________________
conv_direct_4 (Conv2D)          (None, 6, 6, 512)    262656      concatenate_3[0][0]              
__________________________________________________________________________________________________
conv_bypass_4 (Conv2D)          (None, 6, 6, 512)    131584      pool4[0][0]                      
__________________________________________________________________________________________________
batch_normalization_35 (BatchNo (None, 6, 6, 512)    2048        conv_direct_4[0][0]              
__________________________________________________________________________________________________
batch_normalization_36 (BatchNo (None, 6, 6, 512)    2048        conv_bypass_4[0][0]              
__________________________________________________________________________________________________
activation_38 (Activation)      (None, 6, 6, 512)    0           batch_normalization_35[0][0]     
__________________________________________________________________________________________________
activation_39 (Activation)      (None, 6, 6, 512)    0           batch_normalization_36[0][0]     
__________________________________________________________________________________________________
residual4 (Add)                 (None, 6, 6, 512)    0           activation_38[0][0]              
                                                                 activation_39[0][0]              
__________________________________________________________________________________________________
activation_40 (Activation)      (None, 6, 6, 512)    0           residual4[0][0]                  
__________________________________________________________________________________________________
avg_pool (GlobalAveragePooling2 (None, 512)          0           activation_40[0][0]              
__________________________________________________________________________________________________
dense (Dense)                   (None, 50)           25650       avg_pool[0][0]                   
==================================================================================================
Total params: 1,951,034
Trainable params: 1,944,426
Non-trainable params: 6,608
__________________________________________________________________________________________________
Epoch 1/100
199/199 - 96s - loss: 5.0628 - accuracy: 0.1898 - val_loss: 4.8817 - val_accuracy: 0.1182

Epoch 00001: val_loss improved from inf to 4.88170, saving model to modified_v1_training/cp.ckpt
Epoch 2/100
199/199 - 13s - loss: 3.4114 - accuracy: 0.3607 - val_loss: 6.2752 - val_accuracy: 0.1338

Epoch 00002: val_loss did not improve from 4.88170
Epoch 3/100
199/199 - 13s - loss: 2.8154 - accuracy: 0.4421 - val_loss: 5.0344 - val_accuracy: 0.1883

Epoch 00003: val_loss did not improve from 4.88170
Epoch 4/100
199/199 - 13s - loss: 2.4223 - accuracy: 0.5006 - val_loss: 3.7446 - val_accuracy: 0.2604

Epoch 00004: val_loss improved from 4.88170 to 3.74457, saving model to modified_v1_training/cp.ckpt
Epoch 5/100
199/199 - 13s - loss: 2.1625 - accuracy: 0.5456 - val_loss: 4.6060 - val_accuracy: 0.1479

Epoch 00005: val_loss did not improve from 3.74457
Epoch 6/100
199/199 - 13s - loss: 1.9676 - accuracy: 0.5922 - val_loss: 3.7928 - val_accuracy: 0.2512

Epoch 00006: val_loss did not improve from 3.74457
Epoch 7/100
199/199 - 13s - loss: 1.8283 - accuracy: 0.6225 - val_loss: 3.0963 - val_accuracy: 0.3439

Epoch 00007: val_loss improved from 3.74457 to 3.09634, saving model to modified_v1_training/cp.ckpt
Epoch 8/100
199/199 - 13s - loss: 1.7302 - accuracy: 0.6437 - val_loss: 3.8688 - val_accuracy: 0.2795

Epoch 00008: val_loss did not improve from 3.09634
Epoch 9/100
199/199 - 13s - loss: 1.6695 - accuracy: 0.6631 - val_loss: 3.2455 - val_accuracy: 0.3397

Epoch 00009: val_loss did not improve from 3.09634
Epoch 10/100
199/199 - 13s - loss: 1.5891 - accuracy: 0.6857 - val_loss: 5.0643 - val_accuracy: 0.0977

Epoch 00010: val_loss did not improve from 3.09634
Epoch 11/100
199/199 - 13s - loss: 1.5117 - accuracy: 0.7105 - val_loss: 3.2679 - val_accuracy: 0.3001

Epoch 00011: val_loss did not improve from 3.09634
Epoch 12/100
199/199 - 13s - loss: 1.4741 - accuracy: 0.7305 - val_loss: 3.4140 - val_accuracy: 0.3220

Epoch 00012: val_loss did not improve from 3.09634
Epoch 13/100
199/199 - 13s - loss: 1.4613 - accuracy: 0.7393 - val_loss: 3.5959 - val_accuracy: 0.3432

Epoch 00013: val_loss did not improve from 3.09634
Epoch 14/100
199/199 - 13s - loss: 1.4297 - accuracy: 0.7493 - val_loss: 3.2800 - val_accuracy: 0.3376

Epoch 00014: val_loss did not improve from 3.09634
Epoch 15/100
199/199 - 13s - loss: 1.3873 - accuracy: 0.7679 - val_loss: 4.1639 - val_accuracy: 0.2824

Epoch 00015: val_loss did not improve from 3.09634
Epoch 16/100
199/199 - 13s - loss: 1.3685 - accuracy: 0.7767 - val_loss: 4.7910 - val_accuracy: 0.2449

Epoch 00016: val_loss did not improve from 3.09634
Epoch 17/100
199/199 - 13s - loss: 1.3695 - accuracy: 0.7768 - val_loss: 3.9311 - val_accuracy: 0.3057

Epoch 00017: val_loss did not improve from 3.09634
Epoch 18/100
199/199 - 13s - loss: 1.3182 - accuracy: 0.7985 - val_loss: 5.2889 - val_accuracy: 0.2187

Epoch 00018: val_loss did not improve from 3.09634
Epoch 19/100
199/199 - 13s - loss: 1.3434 - accuracy: 0.7943 - val_loss: 4.8958 - val_accuracy: 0.2597

Epoch 00019: val_loss did not improve from 3.09634
Epoch 20/100
199/199 - 13s - loss: 1.3368 - accuracy: 0.7998 - val_loss: 6.6197 - val_accuracy: 0.0814

Epoch 00020: val_loss did not improve from 3.09634
Epoch 21/100
199/199 - 13s - loss: 1.3352 - accuracy: 0.8078 - val_loss: 8.3988 - val_accuracy: 0.1529

Epoch 00021: val_loss did not improve from 3.09634
Epoch 22/100
199/199 - 13s - loss: 1.2946 - accuracy: 0.8201 - val_loss: 5.7453 - val_accuracy: 0.1380

Epoch 00022: val_loss did not improve from 3.09634
Epoch 23/100
199/199 - 13s - loss: 1.3162 - accuracy: 0.8124 - val_loss: 6.3861 - val_accuracy: 0.1423

Epoch 00023: val_loss did not improve from 3.09634
Epoch 24/100
199/199 - 13s - loss: 1.2688 - accuracy: 0.8368 - val_loss: 5.7192 - val_accuracy: 0.1847

Epoch 00024: val_loss did not improve from 3.09634
Epoch 25/100
199/199 - 13s - loss: 1.3227 - accuracy: 0.8184 - val_loss: 6.1892 - val_accuracy: 0.1635

Epoch 00025: val_loss did not improve from 3.09634
Epoch 26/100
199/199 - 13s - loss: 1.1043 - accuracy: 0.9038 - val_loss: 1.6887 - val_accuracy: 0.7424

Epoch 00026: val_loss improved from 3.09634 to 1.68867, saving model to modified_v1_training/cp.ckpt
Epoch 27/100
199/199 - 13s - loss: 0.8546 - accuracy: 0.9793 - val_loss: 1.5987 - val_accuracy: 0.7488

Epoch 00027: val_loss improved from 1.68867 to 1.59873, saving model to modified_v1_training/cp.ckpt
Epoch 28/100
199/199 - 13s - loss: 0.7869 - accuracy: 0.9907 - val_loss: 1.5688 - val_accuracy: 0.7537

Epoch 00028: val_loss improved from 1.59873 to 1.56878, saving model to modified_v1_training/cp.ckpt
Epoch 29/100
199/199 - 13s - loss: 0.7387 - accuracy: 0.9958 - val_loss: 1.5255 - val_accuracy: 0.7707

Epoch 00029: val_loss improved from 1.56878 to 1.52549, saving model to modified_v1_training/cp.ckpt
Epoch 30/100
199/199 - 13s - loss: 0.6998 - accuracy: 0.9977 - val_loss: 1.5042 - val_accuracy: 0.7622

Epoch 00030: val_loss improved from 1.52549 to 1.50421, saving model to modified_v1_training/cp.ckpt
Epoch 31/100
199/199 - 13s - loss: 0.6659 - accuracy: 0.9984 - val_loss: 1.4740 - val_accuracy: 0.7657

Epoch 00031: val_loss improved from 1.50421 to 1.47403, saving model to modified_v1_training/cp.ckpt
Epoch 32/100
199/199 - 13s - loss: 0.6353 - accuracy: 0.9987 - val_loss: 1.4676 - val_accuracy: 0.7679

Epoch 00032: val_loss improved from 1.47403 to 1.46757, saving model to modified_v1_training/cp.ckpt
Epoch 33/100
199/199 - 13s - loss: 0.6070 - accuracy: 0.9994 - val_loss: 1.4503 - val_accuracy: 0.7657

Epoch 00033: val_loss improved from 1.46757 to 1.45029, saving model to modified_v1_training/cp.ckpt
Epoch 34/100
199/199 - 13s - loss: 0.5809 - accuracy: 0.9997 - val_loss: 1.4372 - val_accuracy: 0.7672

Epoch 00034: val_loss improved from 1.45029 to 1.43720, saving model to modified_v1_training/cp.ckpt
Epoch 35/100
199/199 - 13s - loss: 0.5563 - accuracy: 0.9998 - val_loss: 1.4189 - val_accuracy: 0.7636

Epoch 00035: val_loss improved from 1.43720 to 1.41890, saving model to modified_v1_training/cp.ckpt
Epoch 36/100
199/199 - 13s - loss: 0.5332 - accuracy: 0.9998 - val_loss: 1.4017 - val_accuracy: 0.7679

Epoch 00036: val_loss improved from 1.41890 to 1.40172, saving model to modified_v1_training/cp.ckpt
Epoch 37/100
199/199 - 13s - loss: 0.5112 - accuracy: 0.9999 - val_loss: 1.3796 - val_accuracy: 0.7679

Epoch 00037: val_loss improved from 1.40172 to 1.37964, saving model to modified_v1_training/cp.ckpt
Epoch 38/100
199/199 - 13s - loss: 0.4904 - accuracy: 0.9998 - val_loss: 1.3791 - val_accuracy: 0.7643

Epoch 00038: val_loss improved from 1.37964 to 1.37911, saving model to modified_v1_training/cp.ckpt
Epoch 39/100
199/199 - 13s - loss: 0.4705 - accuracy: 1.0000 - val_loss: 1.3584 - val_accuracy: 0.7672

Epoch 00039: val_loss improved from 1.37911 to 1.35841, saving model to modified_v1_training/cp.ckpt
Epoch 40/100
199/199 - 13s - loss: 0.4515 - accuracy: 1.0000 - val_loss: 1.3387 - val_accuracy: 0.7650

Epoch 00040: val_loss improved from 1.35841 to 1.33865, saving model to modified_v1_training/cp.ckpt
Epoch 41/100
199/199 - 13s - loss: 0.4334 - accuracy: 0.9999 - val_loss: 1.3370 - val_accuracy: 0.7650

Epoch 00041: val_loss improved from 1.33865 to 1.33704, saving model to modified_v1_training/cp.ckpt
Epoch 42/100
199/199 - 13s - loss: 0.4160 - accuracy: 1.0000 - val_loss: 1.3282 - val_accuracy: 0.7622

Epoch 00042: val_loss improved from 1.33704 to 1.32823, saving model to modified_v1_training/cp.ckpt
Epoch 43/100
199/199 - 13s - loss: 0.3994 - accuracy: 1.0000 - val_loss: 1.3182 - val_accuracy: 0.7650

Epoch 00043: val_loss improved from 1.32823 to 1.31817, saving model to modified_v1_training/cp.ckpt
Epoch 44/100
199/199 - 13s - loss: 0.3836 - accuracy: 1.0000 - val_loss: 1.2988 - val_accuracy: 0.7672

Epoch 00044: val_loss improved from 1.31817 to 1.29880, saving model to modified_v1_training/cp.ckpt
Epoch 45/100
199/199 - 13s - loss: 0.3683 - accuracy: 1.0000 - val_loss: 1.3053 - val_accuracy: 0.7629

Epoch 00045: val_loss did not improve from 1.29880
Epoch 46/100
199/199 - 13s - loss: 0.3537 - accuracy: 1.0000 - val_loss: 1.2742 - val_accuracy: 0.7665

Epoch 00046: val_loss improved from 1.29880 to 1.27419, saving model to modified_v1_training/cp.ckpt
Epoch 47/100
199/199 - 13s - loss: 0.3397 - accuracy: 1.0000 - val_loss: 1.2651 - val_accuracy: 0.7700

Epoch 00047: val_loss improved from 1.27419 to 1.26514, saving model to modified_v1_training/cp.ckpt
Epoch 48/100
199/199 - 13s - loss: 0.3263 - accuracy: 1.0000 - val_loss: 1.2661 - val_accuracy: 0.7657

Epoch 00048: val_loss did not improve from 1.26514
Epoch 49/100
199/199 - 13s - loss: 0.3134 - accuracy: 1.0000 - val_loss: 1.2480 - val_accuracy: 0.7700

Epoch 00049: val_loss improved from 1.26514 to 1.24802, saving model to modified_v1_training/cp.ckpt
Epoch 50/100
199/199 - 13s - loss: 0.3011 - accuracy: 1.0000 - val_loss: 1.2459 - val_accuracy: 0.7650

Epoch 00050: val_loss improved from 1.24802 to 1.24592, saving model to modified_v1_training/cp.ckpt
Epoch 51/100
199/199 - 13s - loss: 0.2938 - accuracy: 1.0000 - val_loss: 1.2392 - val_accuracy: 0.7764

Epoch 00051: val_loss improved from 1.24592 to 1.23916, saving model to modified_v1_training/cp.ckpt
Epoch 52/100
199/199 - 13s - loss: 0.2926 - accuracy: 1.0000 - val_loss: 1.2399 - val_accuracy: 0.7742

Epoch 00052: val_loss did not improve from 1.23916
Epoch 53/100
199/199 - 13s - loss: 0.2914 - accuracy: 1.0000 - val_loss: 1.2396 - val_accuracy: 0.7749

Epoch 00053: val_loss did not improve from 1.23916
Epoch 54/100
199/199 - 13s - loss: 0.2902 - accuracy: 1.0000 - val_loss: 1.2391 - val_accuracy: 0.7735

Epoch 00054: val_loss improved from 1.23916 to 1.23911, saving model to modified_v1_training/cp.ckpt
Epoch 55/100
199/199 - 13s - loss: 0.2891 - accuracy: 1.0000 - val_loss: 1.2395 - val_accuracy: 0.7714

Epoch 00055: val_loss did not improve from 1.23911
Epoch 56/100
199/199 - 13s - loss: 0.2879 - accuracy: 1.0000 - val_loss: 1.2383 - val_accuracy: 0.7742

Epoch 00056: val_loss improved from 1.23911 to 1.23833, saving model to modified_v1_training/cp.ckpt
Epoch 57/100
199/199 - 13s - loss: 0.2867 - accuracy: 1.0000 - val_loss: 1.2379 - val_accuracy: 0.7735

Epoch 00057: val_loss improved from 1.23833 to 1.23793, saving model to modified_v1_training/cp.ckpt
Epoch 58/100
199/199 - 13s - loss: 0.2856 - accuracy: 1.0000 - val_loss: 1.2372 - val_accuracy: 0.7721

Epoch 00058: val_loss improved from 1.23793 to 1.23723, saving model to modified_v1_training/cp.ckpt
Epoch 59/100
199/199 - 13s - loss: 0.2845 - accuracy: 1.0000 - val_loss: 1.2365 - val_accuracy: 0.7728

Epoch 00059: val_loss improved from 1.23723 to 1.23648, saving model to modified_v1_training/cp.ckpt
Epoch 60/100
199/199 - 13s - loss: 0.2833 - accuracy: 1.0000 - val_loss: 1.2353 - val_accuracy: 0.7771

Epoch 00060: val_loss improved from 1.23648 to 1.23528, saving model to modified_v1_training/cp.ckpt
Epoch 61/100
199/199 - 13s - loss: 0.2822 - accuracy: 1.0000 - val_loss: 1.2341 - val_accuracy: 0.7749

Epoch 00061: val_loss improved from 1.23528 to 1.23406, saving model to modified_v1_training/cp.ckpt
Epoch 62/100
199/199 - 13s - loss: 0.2811 - accuracy: 1.0000 - val_loss: 1.2335 - val_accuracy: 0.7749

Epoch 00062: val_loss improved from 1.23406 to 1.23351, saving model to modified_v1_training/cp.ckpt
Epoch 63/100
199/199 - 13s - loss: 0.2799 - accuracy: 1.0000 - val_loss: 1.2329 - val_accuracy: 0.7721

Epoch 00063: val_loss improved from 1.23351 to 1.23290, saving model to modified_v1_training/cp.ckpt
Epoch 64/100
199/199 - 13s - loss: 0.2788 - accuracy: 1.0000 - val_loss: 1.2319 - val_accuracy: 0.7728

Epoch 00064: val_loss improved from 1.23290 to 1.23192, saving model to modified_v1_training/cp.ckpt
Epoch 65/100
199/199 - 13s - loss: 0.2777 - accuracy: 1.0000 - val_loss: 1.2304 - val_accuracy: 0.7735

Epoch 00065: val_loss improved from 1.23192 to 1.23040, saving model to modified_v1_training/cp.ckpt
Epoch 66/100
199/199 - 13s - loss: 0.2766 - accuracy: 1.0000 - val_loss: 1.2312 - val_accuracy: 0.7721

Epoch 00066: val_loss did not improve from 1.23040
Epoch 67/100
199/199 - 13s - loss: 0.2755 - accuracy: 1.0000 - val_loss: 1.2302 - val_accuracy: 0.7728

Epoch 00067: val_loss improved from 1.23040 to 1.23015, saving model to modified_v1_training/cp.ckpt
Epoch 68/100
199/199 - 13s - loss: 0.2744 - accuracy: 1.0000 - val_loss: 1.2281 - val_accuracy: 0.7728

Epoch 00068: val_loss improved from 1.23015 to 1.22807, saving model to modified_v1_training/cp.ckpt
Epoch 69/100
199/199 - 13s - loss: 0.2733 - accuracy: 1.0000 - val_loss: 1.2273 - val_accuracy: 0.7714

Epoch 00069: val_loss improved from 1.22807 to 1.22731, saving model to modified_v1_training/cp.ckpt
Epoch 70/100
199/199 - 13s - loss: 0.2722 - accuracy: 1.0000 - val_loss: 1.2268 - val_accuracy: 0.7742

Epoch 00070: val_loss improved from 1.22731 to 1.22683, saving model to modified_v1_training/cp.ckpt
Epoch 71/100
199/199 - 13s - loss: 0.2711 - accuracy: 1.0000 - val_loss: 1.2267 - val_accuracy: 0.7714

Epoch 00071: val_loss improved from 1.22683 to 1.22670, saving model to modified_v1_training/cp.ckpt
Epoch 72/100
199/199 - 13s - loss: 0.2700 - accuracy: 1.0000 - val_loss: 1.2261 - val_accuracy: 0.7721

Epoch 00072: val_loss improved from 1.22670 to 1.22611, saving model to modified_v1_training/cp.ckpt
Epoch 73/100
199/199 - 13s - loss: 0.2689 - accuracy: 1.0000 - val_loss: 1.2250 - val_accuracy: 0.7728

Epoch 00073: val_loss improved from 1.22611 to 1.22497, saving model to modified_v1_training/cp.ckpt
Epoch 74/100
199/199 - 13s - loss: 0.2679 - accuracy: 1.0000 - val_loss: 1.2230 - val_accuracy: 0.7728

Epoch 00074: val_loss improved from 1.22497 to 1.22295, saving model to modified_v1_training/cp.ckpt
Epoch 75/100
199/199 - 13s - loss: 0.2668 - accuracy: 1.0000 - val_loss: 1.2244 - val_accuracy: 0.7735

Epoch 00075: val_loss did not improve from 1.22295
Epoch 76/100
199/199 - 13s - loss: 0.2661 - accuracy: 1.0000 - val_loss: 1.2252 - val_accuracy: 0.7757

Epoch 00076: val_loss did not improve from 1.22295
Epoch 77/100
199/199 - 13s - loss: 0.2660 - accuracy: 1.0000 - val_loss: 1.2240 - val_accuracy: 0.7721

Epoch 00077: val_loss did not improve from 1.22295
Epoch 78/100
199/199 - 13s - loss: 0.2659 - accuracy: 1.0000 - val_loss: 1.2242 - val_accuracy: 0.7714

Epoch 00078: val_loss did not improve from 1.22295
Epoch 79/100
199/199 - 13s - loss: 0.2658 - accuracy: 1.0000 - val_loss: 1.2253 - val_accuracy: 0.7714

Epoch 00079: val_loss did not improve from 1.22295
Epoch 80/100
199/199 - 13s - loss: 0.2657 - accuracy: 1.0000 - val_loss: 1.2240 - val_accuracy: 0.7728

Epoch 00080: val_loss did not improve from 1.22295
Epoch 81/100
199/199 - 13s - loss: 0.2656 - accuracy: 1.0000 - val_loss: 1.2241 - val_accuracy: 0.7735

Epoch 00081: val_loss did not improve from 1.22295
Epoch 82/100
199/199 - 13s - loss: 0.2655 - accuracy: 1.0000 - val_loss: 1.2234 - val_accuracy: 0.7728

Epoch 00082: val_loss did not improve from 1.22295
Epoch 83/100
199/199 - 13s - loss: 0.2654 - accuracy: 1.0000 - val_loss: 1.2247 - val_accuracy: 0.7742

Epoch 00083: val_loss did not improve from 1.22295
Epoch 84/100
199/199 - 13s - loss: 0.2653 - accuracy: 1.0000 - val_loss: 1.2233 - val_accuracy: 0.7721

Epoch 00084: val_loss did not improve from 1.22295
Epoch 85/100
199/199 - 13s - loss: 0.2652 - accuracy: 1.0000 - val_loss: 1.2248 - val_accuracy: 0.7721

Epoch 00085: val_loss did not improve from 1.22295
Epoch 86/100
199/199 - 13s - loss: 0.2651 - accuracy: 1.0000 - val_loss: 1.2229 - val_accuracy: 0.7749

Epoch 00086: val_loss improved from 1.22295 to 1.22287, saving model to modified_v1_training/cp.ckpt
Epoch 87/100
199/199 - 13s - loss: 0.2650 - accuracy: 1.0000 - val_loss: 1.2230 - val_accuracy: 0.7721

Epoch 00087: val_loss did not improve from 1.22287
Epoch 88/100
199/199 - 13s - loss: 0.2649 - accuracy: 1.0000 - val_loss: 1.2225 - val_accuracy: 0.7742

Epoch 00088: val_loss improved from 1.22287 to 1.22252, saving model to modified_v1_training/cp.ckpt
Epoch 89/100
199/199 - 13s - loss: 0.2648 - accuracy: 1.0000 - val_loss: 1.2231 - val_accuracy: 0.7728

Epoch 00089: val_loss did not improve from 1.22252
Epoch 90/100
199/199 - 13s - loss: 0.2647 - accuracy: 1.0000 - val_loss: 1.2234 - val_accuracy: 0.7742

Epoch 00090: val_loss did not improve from 1.22252
Epoch 91/100
199/199 - 13s - loss: 0.2646 - accuracy: 1.0000 - val_loss: 1.2226 - val_accuracy: 0.7749

Epoch 00091: val_loss did not improve from 1.22252
Epoch 92/100
199/199 - 13s - loss: 0.2644 - accuracy: 1.0000 - val_loss: 1.2228 - val_accuracy: 0.7721

Epoch 00092: val_loss did not improve from 1.22252
Epoch 93/100
199/199 - 13s - loss: 0.2643 - accuracy: 1.0000 - val_loss: 1.2216 - val_accuracy: 0.7735

Epoch 00093: val_loss improved from 1.22252 to 1.22155, saving model to modified_v1_training/cp.ckpt
Epoch 94/100
199/199 - 13s - loss: 0.2642 - accuracy: 1.0000 - val_loss: 1.2238 - val_accuracy: 0.7757

Epoch 00094: val_loss did not improve from 1.22155
Epoch 95/100
199/199 - 13s - loss: 0.2641 - accuracy: 1.0000 - val_loss: 1.2227 - val_accuracy: 0.7742

Epoch 00095: val_loss did not improve from 1.22155
Epoch 96/100
199/199 - 13s - loss: 0.2640 - accuracy: 1.0000 - val_loss: 1.2235 - val_accuracy: 0.7735

Epoch 00096: val_loss did not improve from 1.22155
Epoch 97/100
199/199 - 13s - loss: 0.2639 - accuracy: 1.0000 - val_loss: 1.2241 - val_accuracy: 0.7714

Epoch 00097: val_loss did not improve from 1.22155
Epoch 98/100
199/199 - 13s - loss: 0.2638 - accuracy: 1.0000 - val_loss: 1.2227 - val_accuracy: 0.7749

Epoch 00098: val_loss did not improve from 1.22155
Epoch 99/100
199/199 - 13s - loss: 0.2637 - accuracy: 1.0000 - val_loss: 1.2234 - val_accuracy: 0.7714

Epoch 00099: val_loss did not improve from 1.22155
Epoch 100/100
199/199 - 13s - loss: 0.2636 - accuracy: 1.0000 - val_loss: 1.2226 - val_accuracy: 0.7742

Epoch 00100: val_loss did not improve from 1.22155
Total time taken to train in seconds: 1798.9612362384796
Model: "model_1"
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            [(None, 224, 224, 3) 0                                            
__________________________________________________________________________________________________
conv1 (Conv2D)                  (None, 112, 112, 64) 4864        input_2[0][0]                    
__________________________________________________________________________________________________
batch_normalization_37 (BatchNo (None, 112, 112, 64) 256         conv1[0][0]                      
__________________________________________________________________________________________________
activation_41 (Activation)      (None, 112, 112, 64) 0           batch_normalization_37[0][0]     
__________________________________________________________________________________________________
pool1 (MaxPooling2D)            (None, 55, 55, 64)   0           activation_41[0][0]              
__________________________________________________________________________________________________
nu_inception_1_3x3_1_3 (Conv2D) (None, 55, 55, 8)    4616        pool1[0][0]                      
__________________________________________________________________________________________________
batch_normalization_42 (BatchNo (None, 55, 55, 8)    32          nu_inception_1_3x3_1_3[0][0]     
__________________________________________________________________________________________________
activation_46 (Activation)      (None, 55, 55, 8)    0           batch_normalization_42[0][0]     
__________________________________________________________________________________________________
nu_inception_1_3x3_1 (Conv2D)   (None, 55, 55, 8)    4616        pool1[0][0]                      
__________________________________________________________________________________________________
nu_inception_1_3x3_2_3 (Conv2D) (None, 55, 55, 8)    584         activation_46[0][0]              
__________________________________________________________________________________________________
batch_normalization_40 (BatchNo (None, 55, 55, 8)    32          nu_inception_1_3x3_1[0][0]       
__________________________________________________________________________________________________
batch_normalization_43 (BatchNo (None, 55, 55, 8)    32          nu_inception_1_3x3_2_3[0][0]     
__________________________________________________________________________________________________
activation_44 (Activation)      (None, 55, 55, 8)    0           batch_normalization_40[0][0]     
__________________________________________________________________________________________________
activation_47 (Activation)      (None, 55, 55, 8)    0           batch_normalization_43[0][0]     
__________________________________________________________________________________________________
nu_inception_1_1x1 (Conv2D)     (None, 55, 55, 16)   1040        pool1[0][0]                      
__________________________________________________________________________________________________
nu_inception_1_3x3 (Conv2D)     (None, 55, 55, 32)   18464       pool1[0][0]                      
__________________________________________________________________________________________________
nu_inception_1_3x3_2 (Conv2D)   (None, 55, 55, 8)    584         activation_44[0][0]              
__________________________________________________________________________________________________
nu_inception_1_3x3_3_3 (Conv2D) (None, 55, 55, 8)    584         activation_47[0][0]              
__________________________________________________________________________________________________
batch_normalization_38 (BatchNo (None, 55, 55, 16)   64          nu_inception_1_1x1[0][0]         
__________________________________________________________________________________________________
batch_normalization_39 (BatchNo (None, 55, 55, 32)   128         nu_inception_1_3x3[0][0]         
__________________________________________________________________________________________________
batch_normalization_41 (BatchNo (None, 55, 55, 8)    32          nu_inception_1_3x3_2[0][0]       
__________________________________________________________________________________________________
batch_normalization_44 (BatchNo (None, 55, 55, 8)    32          nu_inception_1_3x3_3_3[0][0]     
__________________________________________________________________________________________________
activation_42 (Activation)      (None, 55, 55, 16)   0           batch_normalization_38[0][0]     
__________________________________________________________________________________________________
activation_43 (Activation)      (None, 55, 55, 32)   0           batch_normalization_39[0][0]     
__________________________________________________________________________________________________
activation_45 (Activation)      (None, 55, 55, 8)    0           batch_normalization_41[0][0]     
__________________________________________________________________________________________________
activation_48 (Activation)      (None, 55, 55, 8)    0           batch_normalization_44[0][0]     
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 55, 55, 64)   0           activation_42[0][0]              
                                                                 activation_43[0][0]              
                                                                 activation_45[0][0]              
                                                                 activation_48[0][0]              
__________________________________________________________________________________________________
conv_direct_1 (Conv2D)          (None, 55, 55, 64)   4160        concatenate_4[0][0]              
__________________________________________________________________________________________________
conv_bypass_1 (Conv2D)          (None, 55, 55, 64)   4160        pool1[0][0]                      
__________________________________________________________________________________________________
batch_normalization_45 (BatchNo (None, 55, 55, 64)   256         conv_direct_1[0][0]              
__________________________________________________________________________________________________
batch_normalization_46 (BatchNo (None, 55, 55, 64)   256         conv_bypass_1[0][0]              
__________________________________________________________________________________________________
activation_49 (Activation)      (None, 55, 55, 64)   0           batch_normalization_45[0][0]     
__________________________________________________________________________________________________
activation_50 (Activation)      (None, 55, 55, 64)   0           batch_normalization_46[0][0]     
__________________________________________________________________________________________________
residual1 (Add)                 (None, 55, 55, 64)   0           activation_49[0][0]              
                                                                 activation_50[0][0]              
__________________________________________________________________________________________________
activation_51 (Activation)      (None, 55, 55, 64)   0           residual1[0][0]                  
__________________________________________________________________________________________________
pool2 (MaxPooling2D)            (None, 27, 27, 64)   0           activation_51[0][0]              
__________________________________________________________________________________________________
nu_inception_2_3x3_1_3 (Conv2D) (None, 27, 27, 16)   9232        pool2[0][0]                      
__________________________________________________________________________________________________
batch_normalization_51 (BatchNo (None, 27, 27, 16)   64          nu_inception_2_3x3_1_3[0][0]     
__________________________________________________________________________________________________
activation_56 (Activation)      (None, 27, 27, 16)   0           batch_normalization_51[0][0]     
__________________________________________________________________________________________________
nu_inception_2_3x3_1 (Conv2D)   (None, 27, 27, 16)   9232        pool2[0][0]                      
__________________________________________________________________________________________________
nu_inception_2_3x3_2_3 (Conv2D) (None, 27, 27, 16)   2320        activation_56[0][0]              
__________________________________________________________________________________________________
batch_normalization_49 (BatchNo (None, 27, 27, 16)   64          nu_inception_2_3x3_1[0][0]       
__________________________________________________________________________________________________
batch_normalization_52 (BatchNo (None, 27, 27, 16)   64          nu_inception_2_3x3_2_3[0][0]     
__________________________________________________________________________________________________
activation_54 (Activation)      (None, 27, 27, 16)   0           batch_normalization_49[0][0]     
__________________________________________________________________________________________________
activation_57 (Activation)      (None, 27, 27, 16)   0           batch_normalization_52[0][0]     
__________________________________________________________________________________________________
nu_inception_2_1x1 (Conv2D)     (None, 27, 27, 32)   2080        pool2[0][0]                      
__________________________________________________________________________________________________
nu_inception_2_3x3 (Conv2D)     (None, 27, 27, 64)   36928       pool2[0][0]                      
__________________________________________________________________________________________________
nu_inception_2_3x3_2 (Conv2D)   (None, 27, 27, 16)   2320        activation_54[0][0]              
__________________________________________________________________________________________________
nu_inception_2_3x3_3_3 (Conv2D) (None, 27, 27, 16)   2320        activation_57[0][0]              
__________________________________________________________________________________________________
batch_normalization_47 (BatchNo (None, 27, 27, 32)   128         nu_inception_2_1x1[0][0]         
__________________________________________________________________________________________________
batch_normalization_48 (BatchNo (None, 27, 27, 64)   256         nu_inception_2_3x3[0][0]         
__________________________________________________________________________________________________
batch_normalization_50 (BatchNo (None, 27, 27, 16)   64          nu_inception_2_3x3_2[0][0]       
__________________________________________________________________________________________________
batch_normalization_53 (BatchNo (None, 27, 27, 16)   64          nu_inception_2_3x3_3_3[0][0]     
__________________________________________________________________________________________________
activation_52 (Activation)      (None, 27, 27, 32)   0           batch_normalization_47[0][0]     
__________________________________________________________________________________________________
activation_53 (Activation)      (None, 27, 27, 64)   0           batch_normalization_48[0][0]     
__________________________________________________________________________________________________
activation_55 (Activation)      (None, 27, 27, 16)   0           batch_normalization_50[0][0]     
__________________________________________________________________________________________________
activation_58 (Activation)      (None, 27, 27, 16)   0           batch_normalization_53[0][0]     
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 27, 27, 128)  0           activation_52[0][0]              
                                                                 activation_53[0][0]              
                                                                 activation_55[0][0]              
                                                                 activation_58[0][0]              
__________________________________________________________________________________________________
conv_direct_2 (Conv2D)          (None, 27, 27, 128)  16512       concatenate_5[0][0]              
__________________________________________________________________________________________________
conv_bypass_2 (Conv2D)          (None, 27, 27, 128)  8320        pool2[0][0]                      
__________________________________________________________________________________________________
batch_normalization_54 (BatchNo (None, 27, 27, 128)  512         conv_direct_2[0][0]              
__________________________________________________________________________________________________
batch_normalization_55 (BatchNo (None, 27, 27, 128)  512         conv_bypass_2[0][0]              
__________________________________________________________________________________________________
activation_59 (Activation)      (None, 27, 27, 128)  0           batch_normalization_54[0][0]     
__________________________________________________________________________________________________
activation_60 (Activation)      (None, 27, 27, 128)  0           batch_normalization_55[0][0]     
__________________________________________________________________________________________________
residual2 (Add)                 (None, 27, 27, 128)  0           activation_59[0][0]              
                                                                 activation_60[0][0]              
__________________________________________________________________________________________________
activation_61 (Activation)      (None, 27, 27, 128)  0           residual2[0][0]                  
__________________________________________________________________________________________________
pool3 (MaxPooling2D)            (None, 13, 13, 128)  0           activation_61[0][0]              
__________________________________________________________________________________________________
nu_inception_3_3x3_1_3 (Conv2D) (None, 13, 13, 32)   36896       pool3[0][0]                      
__________________________________________________________________________________________________
batch_normalization_60 (BatchNo (None, 13, 13, 32)   128         nu_inception_3_3x3_1_3[0][0]     
__________________________________________________________________________________________________
activation_66 (Activation)      (None, 13, 13, 32)   0           batch_normalization_60[0][0]     
__________________________________________________________________________________________________
nu_inception_3_3x3_1 (Conv2D)   (None, 13, 13, 32)   36896       pool3[0][0]                      
__________________________________________________________________________________________________
nu_inception_3_3x3_2_3 (Conv2D) (None, 13, 13, 32)   9248        activation_66[0][0]              
__________________________________________________________________________________________________
batch_normalization_58 (BatchNo (None, 13, 13, 32)   128         nu_inception_3_3x3_1[0][0]       
__________________________________________________________________________________________________
batch_normalization_61 (BatchNo (None, 13, 13, 32)   128         nu_inception_3_3x3_2_3[0][0]     
__________________________________________________________________________________________________
activation_64 (Activation)      (None, 13, 13, 32)   0           batch_normalization_58[0][0]     
__________________________________________________________________________________________________
activation_67 (Activation)      (None, 13, 13, 32)   0           batch_normalization_61[0][0]     
__________________________________________________________________________________________________
nu_inception_3_1x1 (Conv2D)     (None, 13, 13, 64)   8256        pool3[0][0]                      
__________________________________________________________________________________________________
nu_inception_3_3x3 (Conv2D)     (None, 13, 13, 128)  147584      pool3[0][0]                      
__________________________________________________________________________________________________
nu_inception_3_3x3_2 (Conv2D)   (None, 13, 13, 32)   9248        activation_64[0][0]              
__________________________________________________________________________________________________
nu_inception_3_3x3_3_3 (Conv2D) (None, 13, 13, 32)   9248        activation_67[0][0]              
__________________________________________________________________________________________________
batch_normalization_56 (BatchNo (None, 13, 13, 64)   256         nu_inception_3_1x1[0][0]         
__________________________________________________________________________________________________
batch_normalization_57 (BatchNo (None, 13, 13, 128)  512         nu_inception_3_3x3[0][0]         
__________________________________________________________________________________________________
batch_normalization_59 (BatchNo (None, 13, 13, 32)   128         nu_inception_3_3x3_2[0][0]       
__________________________________________________________________________________________________
batch_normalization_62 (BatchNo (None, 13, 13, 32)   128         nu_inception_3_3x3_3_3[0][0]     
__________________________________________________________________________________________________
activation_62 (Activation)      (None, 13, 13, 64)   0           batch_normalization_56[0][0]     
__________________________________________________________________________________________________
activation_63 (Activation)      (None, 13, 13, 128)  0           batch_normalization_57[0][0]     
__________________________________________________________________________________________________
activation_65 (Activation)      (None, 13, 13, 32)   0           batch_normalization_59[0][0]     
__________________________________________________________________________________________________
activation_68 (Activation)      (None, 13, 13, 32)   0           batch_normalization_62[0][0]     
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 13, 13, 256)  0           activation_62[0][0]              
                                                                 activation_63[0][0]              
                                                                 activation_65[0][0]              
                                                                 activation_68[0][0]              
__________________________________________________________________________________________________
conv_direct_3 (Conv2D)          (None, 13, 13, 256)  65792       concatenate_6[0][0]              
__________________________________________________________________________________________________
conv_bypass_3 (Conv2D)          (None, 13, 13, 256)  33024       pool3[0][0]                      
__________________________________________________________________________________________________
batch_normalization_63 (BatchNo (None, 13, 13, 256)  1024        conv_direct_3[0][0]              
__________________________________________________________________________________________________
batch_normalization_64 (BatchNo (None, 13, 13, 256)  1024        conv_bypass_3[0][0]              
__________________________________________________________________________________________________
activation_69 (Activation)      (None, 13, 13, 256)  0           batch_normalization_63[0][0]     
__________________________________________________________________________________________________
activation_70 (Activation)      (None, 13, 13, 256)  0           batch_normalization_64[0][0]     
__________________________________________________________________________________________________
residual3 (Add)                 (None, 13, 13, 256)  0           activation_69[0][0]              
                                                                 activation_70[0][0]              
__________________________________________________________________________________________________
activation_71 (Activation)      (None, 13, 13, 256)  0           residual3[0][0]                  
__________________________________________________________________________________________________
pool4 (MaxPooling2D)            (None, 6, 6, 256)    0           activation_71[0][0]              
__________________________________________________________________________________________________
nu_inception_4_3x3_1_3 (Conv2D) (None, 6, 6, 64)     147520      pool4[0][0]                      
__________________________________________________________________________________________________
batch_normalization_69 (BatchNo (None, 6, 6, 64)     256         nu_inception_4_3x3_1_3[0][0]     
__________________________________________________________________________________________________
activation_76 (Activation)      (None, 6, 6, 64)     0           batch_normalization_69[0][0]     
__________________________________________________________________________________________________
nu_inception_4_3x3_1 (Conv2D)   (None, 6, 6, 64)     147520      pool4[0][0]                      
__________________________________________________________________________________________________
nu_inception_4_3x3_2_3 (Conv2D) (None, 6, 6, 64)     36928       activation_76[0][0]              
__________________________________________________________________________________________________
batch_normalization_67 (BatchNo (None, 6, 6, 64)     256         nu_inception_4_3x3_1[0][0]       
__________________________________________________________________________________________________
batch_normalization_70 (BatchNo (None, 6, 6, 64)     256         nu_inception_4_3x3_2_3[0][0]     
__________________________________________________________________________________________________
activation_74 (Activation)      (None, 6, 6, 64)     0           batch_normalization_67[0][0]     
__________________________________________________________________________________________________
activation_77 (Activation)      (None, 6, 6, 64)     0           batch_normalization_70[0][0]     
__________________________________________________________________________________________________
nu_inception_4_1x1 (Conv2D)     (None, 6, 6, 128)    32896       pool4[0][0]                      
__________________________________________________________________________________________________
nu_inception_4_3x3 (Conv2D)     (None, 6, 6, 256)    590080      pool4[0][0]                      
__________________________________________________________________________________________________
nu_inception_4_3x3_2 (Conv2D)   (None, 6, 6, 64)     36928       activation_74[0][0]              
__________________________________________________________________________________________________
nu_inception_4_3x3_3_3 (Conv2D) (None, 6, 6, 64)     36928       activation_77[0][0]              
__________________________________________________________________________________________________
batch_normalization_65 (BatchNo (None, 6, 6, 128)    512         nu_inception_4_1x1[0][0]         
__________________________________________________________________________________________________
batch_normalization_66 (BatchNo (None, 6, 6, 256)    1024        nu_inception_4_3x3[0][0]         
__________________________________________________________________________________________________
batch_normalization_68 (BatchNo (None, 6, 6, 64)     256         nu_inception_4_3x3_2[0][0]       
__________________________________________________________________________________________________
batch_normalization_71 (BatchNo (None, 6, 6, 64)     256         nu_inception_4_3x3_3_3[0][0]     
__________________________________________________________________________________________________
activation_72 (Activation)      (None, 6, 6, 128)    0           batch_normalization_65[0][0]     
__________________________________________________________________________________________________
activation_73 (Activation)      (None, 6, 6, 256)    0           batch_normalization_66[0][0]     
__________________________________________________________________________________________________
activation_75 (Activation)      (None, 6, 6, 64)     0           batch_normalization_68[0][0]     
__________________________________________________________________________________________________
activation_78 (Activation)      (None, 6, 6, 64)     0           batch_normalization_71[0][0]     
__________________________________________________________________________________________________
concatenate_7 (Concatenate)     (None, 6, 6, 512)    0           activation_72[0][0]              
                                                                 activation_73[0][0]              
                                                                 activation_75[0][0]              
                                                                 activation_78[0][0]              
__________________________________________________________________________________________________
conv_direct_4 (Conv2D)          (None, 6, 6, 512)    262656      concatenate_7[0][0]              
__________________________________________________________________________________________________
conv_bypass_4 (Conv2D)          (None, 6, 6, 512)    131584      pool4[0][0]                      
__________________________________________________________________________________________________
batch_normalization_72 (BatchNo (None, 6, 6, 512)    2048        conv_direct_4[0][0]              
__________________________________________________________________________________________________
batch_normalization_73 (BatchNo (None, 6, 6, 512)    2048        conv_bypass_4[0][0]              
__________________________________________________________________________________________________
activation_79 (Activation)      (None, 6, 6, 512)    0           batch_normalization_72[0][0]     
__________________________________________________________________________________________________
activation_80 (Activation)      (None, 6, 6, 512)    0           batch_normalization_73[0][0]     
__________________________________________________________________________________________________
residual4 (Add)                 (None, 6, 6, 512)    0           activation_79[0][0]              
                                                                 activation_80[0][0]              
__________________________________________________________________________________________________
activation_81 (Activation)      (None, 6, 6, 512)    0           residual4[0][0]                  
__________________________________________________________________________________________________
avg_pool (GlobalAveragePooling2 (None, 512)          0           activation_81[0][0]              
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 50)           25650       avg_pool[0][0]                   
==================================================================================================
Total params: 1,951,034
Trainable params: 1,944,426
Non-trainable params: 6,608
__________________________________________________________________________________________________
 1/25 [>.............................] - ETA: 1:42 - loss: 1.1693 - accuracy: 0.7656 2/25 [=>............................] - ETA: 10s - loss: 1.1793 - accuracy: 0.7734  3/25 [==>...........................] - ETA: 9s - loss: 1.0395 - accuracy: 0.8177  4/25 [===>..........................] - ETA: 8s - loss: 1.1156 - accuracy: 0.8086 5/25 [=====>........................] - ETA: 7s - loss: 1.0982 - accuracy: 0.8125 6/25 [======>.......................] - ETA: 7s - loss: 1.1641 - accuracy: 0.7995 7/25 [=======>......................] - ETA: 7s - loss: 1.1851 - accuracy: 0.7969 8/25 [========>.....................] - ETA: 6s - loss: 1.1679 - accuracy: 0.7969 9/25 [=========>....................] - ETA: 6s - loss: 1.2069 - accuracy: 0.789910/25 [===========>..................] - ETA: 5s - loss: 1.2075 - accuracy: 0.792211/25 [============>.................] - ETA: 5s - loss: 1.1868 - accuracy: 0.795512/25 [=============>................] - ETA: 5s - loss: 1.1748 - accuracy: 0.798213/25 [==============>...............] - ETA: 4s - loss: 1.2036 - accuracy: 0.796914/25 [===============>..............] - ETA: 4s - loss: 1.1922 - accuracy: 0.801315/25 [=================>............] - ETA: 3s - loss: 1.1688 - accuracy: 0.803116/25 [==================>...........] - ETA: 3s - loss: 1.1396 - accuracy: 0.808617/25 [===================>..........] - ETA: 2s - loss: 1.1336 - accuracy: 0.808818/25 [====================>.........] - ETA: 2s - loss: 1.1165 - accuracy: 0.809020/25 [=======================>......] - ETA: 1s - loss: 1.1329 - accuracy: 0.806221/25 [========================>.....] - ETA: 1s - loss: 1.1429 - accuracy: 0.807323/25 [==========================>...] - ETA: 0s - loss: 1.1329 - accuracy: 0.808425/25 [==============================] - ETA: 0s - loss: 1.1074 - accuracy: 0.811525/25 [==============================] - 11s 276ms/step - loss: 1.1074 - accuracy: 0.8115
